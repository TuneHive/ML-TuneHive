{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true,"include_colab_link":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/zeev-haydar/ML-TuneHive/blob/model-development%2Fhaidar/model-dev/preprocessing-modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1TZ3huHSIkB","outputId":"3a68ad79-241c-445a-a509-0e1b6b870fa5","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:41:30.810695Z","iopub.execute_input":"2024-12-12T15:41:30.811133Z","iopub.status.idle":"2024-12-12T15:41:31.932361Z","shell.execute_reply.started":"2024-12-12T15:41:30.811065Z","shell.execute_reply":"2024-12-12T15:41:31.931550Z"}},"outputs":[{"name":"stdout","text":"Thu Dec 12 15:41:31 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   48C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   51C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Preprocessing and Modeling","metadata":{"id":"k7iFBw8Iau9f"}},{"cell_type":"markdown","source":"## Import required modules","metadata":{"id":"R7tdLXmCau9h"}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow_datasets as tfds\n\nfrom keras.api.layers import Dense, Embedding, GRU, LeakyReLU, Concatenate, Masking, Layer, StringLookup, Normalization, BatchNormalization, Attention, Dropout, Lambda\n\nfrom keras.api import Input\n\nfrom keras.api.models import Model\n\nfrom keras.api.losses import SparseCategoricalCrossentropy\n\nfrom keras.api.metrics import SparseCategoricalAccuracy, Mean, TopKCategoricalAccuracy\n\n# from transformers.models.bert import TFBertTokenizer, TFBertEmbeddings  # embedding and tokenizer for description/nlp related stufff\n\nfrom keras.api.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\n\nimport numpy as np\n\nimport ast","metadata":{"id":"ni2TKE2oau9i","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:41:32.532621Z","iopub.execute_input":"2024-12-12T15:41:32.532891Z","iopub.status.idle":"2024-12-12T15:41:44.907715Z","shell.execute_reply.started":"2024-12-12T15:41:32.532864Z","shell.execute_reply":"2024-12-12T15:41:44.907059Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Preprocessing","metadata":{"id":"PEtBlEo2au9j"}},{"cell_type":"markdown","source":"### Load CSV","metadata":{"id":"hkeNofysau9k"}},{"cell_type":"code","source":"# For Running in Google Colab\n\n# \"https://raw.githubusercontent.com/{user}/{repo}/main/{src_dir}/{file}\"\n\nurl = \"https://raw.githubusercontent.com/zeev-haydar/ML-TuneHive/main/model-dev/data/session-data.csv\"\n\n!wget --no-cache --backups=1 {url}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhWy8OaOaxMX","outputId":"4868560b-25dd-46bb-969a-7bddf1508b4f","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:41:53.340310Z","iopub.execute_input":"2024-12-12T15:41:53.340975Z","iopub.status.idle":"2024-12-12T15:41:57.221478Z","shell.execute_reply.started":"2024-12-12T15:41:53.340944Z","shell.execute_reply":"2024-12-12T15:41:57.220641Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"--2024-12-12 15:41:54--  https://raw.githubusercontent.com/zeev-haydar/ML-TuneHive/main/model-dev/data/session-data.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 21952709 (21M) [text/plain]\nFailed to rename session-data.csv to session-data.csv.1: (2) No such file or directory\nSaving to: 'session-data.csv'\n\nsession-data.csv    100%[===================>]  20.94M  38.1MB/s    in 0.5s    \n\n2024-12-12 15:41:57 (38.1 MB/s) - 'session-data.csv' saved [21952709/21952709]\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import keras\n\nimport os\n\nprint(keras.__version__)\n\n\n\n# root_path = \"data\"\n\nroot_path = \"\" # if using colab\n\ndf = pd.read_csv(os.path.join(root_path, \"session-data.csv\"))\n\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":947},"id":"hFAqYSf1au9k","outputId":"c024e548-6dd9-48ee-8490-b72022e84286","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:41:58.903303Z","iopub.execute_input":"2024-12-12T15:41:58.904072Z","iopub.status.idle":"2024-12-12T15:41:59.368099Z","shell.execute_reply.started":"2024-12-12T15:41:58.904040Z","shell.execute_reply":"2024-12-12T15:41:59.367094Z"}},"outputs":[{"name":"stdout","text":"3.3.3\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       index_x                                       SongID  \\\n0            0                 Twenty Five MilesEdwin Starr   \n1            1                       Devil's EyesGreyhounds   \n2            2                          Pussy and PizzaMurs   \n3            8                   Our Special PlaceThe Heavy   \n4           10      Make Peace and be FreePerfect Confusion   \n...        ...                                          ...   \n50013    62902  From Me To You - Remastered 2009The Beatles   \n50014    62903  And I Love Her - Remastered 2009The Beatles   \n50015    62904  Ticket To Ride - Remastered 2009The Beatles   \n50016    62905   Come Together - Remastered 2009The Beatles   \n50017    62906      Penny Lane - Remastered 2009The Beatles   \n\n          TimeStamp_Central        Performer_x  \\\n0      5/25/2021 5:18:00 PM        Edwin Starr   \n1      5/25/2021 5:15:00 PM         Greyhounds   \n2      5/25/2021 5:12:00 PM               Murs   \n3      5/25/2021 4:46:00 PM          The Heavy   \n4      5/25/2021 4:39:00 PM  Perfect Confusion   \n...                     ...                ...   \n50013  1/1/2017 10:04:00 AM        The Beatles   \n50014  1/1/2017 10:01:00 AM        The Beatles   \n50015   1/1/2017 9:58:00 AM        The Beatles   \n50016   1/1/2017 9:54:00 AM        The Beatles   \n50017   1/1/2017 9:51:00 AM        The Beatles   \n\n                                         Album  \\\n0                                     25 Miles   \n1                               Change of Pace   \n2                             Have a Nice Life   \n3             Great Vengeance and Furious Fire   \n4                            Perfect Confusion   \n...                                        ...   \n50013  Past Masters (Vols. 1 & 2 / Remastered)   \n50014          A Hard Day's Night (Remastered)   \n50015                       Help! (Remastered)   \n50016                  Abbey Road (Remastered)   \n50017        Magical Mystery Tour (Remastered)   \n\n                                 Song_x        TimeStamp_UTC  index_y  \\\n0                     Twenty Five Miles  2021-05-25 23:18:00     9761   \n1                          Devil's Eyes  2021-05-25 23:15:00      206   \n2                       Pussy and Pizza  2021-05-25 23:12:00     6404   \n3                     Our Special Place  2021-05-25 22:46:00     6205   \n4                Make Peace and be Free  2021-05-25 22:39:00     6051   \n...                                 ...                  ...      ...   \n50013  From Me To You - Remastered 2009  2017-01-01 16:04:00     5693   \n50014  And I Love Her - Remastered 2009  2017-01-01 16:01:00      360   \n50015  Ticket To Ride - Remastered 2009  2017-01-01 15:58:00     9715   \n50016   Come Together - Remastered 2009  2017-01-01 15:54:00     7425   \n50017      Penny Lane - Remastered 2009  2017-01-01 15:51:00     4401   \n\n             Performer_y                            Song_y  ... mode  \\\n0            Edwin Starr                 Twenty Five Miles  ...  1.0   \n1             Greyhounds                      Devil's Eyes  ...  0.0   \n2                   Murs                   Pussy and Pizza  ...  1.0   \n3              The Heavy                 Our Special Place  ...  1.0   \n4      Perfect Confusion            Make Peace and be Free  ...  1.0   \n...                  ...                               ...  ...  ...   \n50013        The Beatles  From Me To You - Remastered 2009  ...  1.0   \n50014        The Beatles  And I Love Her - Remastered 2009  ...  0.0   \n50015        The Beatles  Ticket To Ride - Remastered 2009  ...  1.0   \n50016        The Beatles   Come Together - Remastered 2009  ...  0.0   \n50017        The Beatles      Penny Lane - Remastered 2009  ...  1.0   \n\n      speechiness acousticness  instrumentalness  liveness  valence    tempo  \\\n0          0.0607       0.0595          0.000015    0.2240    0.964  124.567   \n1          0.0456       0.3540          0.000414    0.0974    0.858  113.236   \n2          0.0659       0.0708          0.000004    0.0780    0.381   93.991   \n3          0.0386       0.2720          0.003610    0.0991    0.939  193.996   \n4          0.0315       0.0138          0.000017    0.0649    0.431   78.037   \n...           ...          ...               ...       ...      ...      ...   \n50013      0.0309       0.6130          0.000000    0.2690    0.966  136.125   \n50014      0.0337       0.6400          0.000000    0.0681    0.636  113.312   \n50015      0.0678       0.0457          0.000000    0.2330    0.749  123.419   \n50016      0.0393       0.0302          0.248000    0.0926    0.187  165.007   \n50017      0.0316       0.2120          0.026000    0.1360    0.490  113.038   \n\n       time_signature       session_3_hour  session_id  \n0                 4.0  2021-05-25 21:00:00        4332  \n1                 4.0  2021-05-25 21:00:00        4332  \n2                 4.0  2021-05-25 21:00:00        4332  \n3                 4.0  2021-05-25 21:00:00        4332  \n4                 4.0  2021-05-25 21:00:00        4332  \n...               ...                  ...         ...  \n50013             4.0  2017-01-01 15:00:00           0  \n50014             4.0  2017-01-01 15:00:00           0  \n50015             4.0  2017-01-01 15:00:00           0  \n50016             4.0  2017-01-01 15:00:00           0  \n50017             4.0  2017-01-01 15:00:00           0  \n\n[50018 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index_x</th>\n      <th>SongID</th>\n      <th>TimeStamp_Central</th>\n      <th>Performer_x</th>\n      <th>Album</th>\n      <th>Song_x</th>\n      <th>TimeStamp_UTC</th>\n      <th>index_y</th>\n      <th>Performer_y</th>\n      <th>Song_y</th>\n      <th>...</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>session_3_hour</th>\n      <th>session_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Twenty Five MilesEdwin Starr</td>\n      <td>5/25/2021 5:18:00 PM</td>\n      <td>Edwin Starr</td>\n      <td>25 Miles</td>\n      <td>Twenty Five Miles</td>\n      <td>2021-05-25 23:18:00</td>\n      <td>9761</td>\n      <td>Edwin Starr</td>\n      <td>Twenty Five Miles</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0607</td>\n      <td>0.0595</td>\n      <td>0.000015</td>\n      <td>0.2240</td>\n      <td>0.964</td>\n      <td>124.567</td>\n      <td>4.0</td>\n      <td>2021-05-25 21:00:00</td>\n      <td>4332</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Devil's EyesGreyhounds</td>\n      <td>5/25/2021 5:15:00 PM</td>\n      <td>Greyhounds</td>\n      <td>Change of Pace</td>\n      <td>Devil's Eyes</td>\n      <td>2021-05-25 23:15:00</td>\n      <td>206</td>\n      <td>Greyhounds</td>\n      <td>Devil's Eyes</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0456</td>\n      <td>0.3540</td>\n      <td>0.000414</td>\n      <td>0.0974</td>\n      <td>0.858</td>\n      <td>113.236</td>\n      <td>4.0</td>\n      <td>2021-05-25 21:00:00</td>\n      <td>4332</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Pussy and PizzaMurs</td>\n      <td>5/25/2021 5:12:00 PM</td>\n      <td>Murs</td>\n      <td>Have a Nice Life</td>\n      <td>Pussy and Pizza</td>\n      <td>2021-05-25 23:12:00</td>\n      <td>6404</td>\n      <td>Murs</td>\n      <td>Pussy and Pizza</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0659</td>\n      <td>0.0708</td>\n      <td>0.000004</td>\n      <td>0.0780</td>\n      <td>0.381</td>\n      <td>93.991</td>\n      <td>4.0</td>\n      <td>2021-05-25 21:00:00</td>\n      <td>4332</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>Our Special PlaceThe Heavy</td>\n      <td>5/25/2021 4:46:00 PM</td>\n      <td>The Heavy</td>\n      <td>Great Vengeance and Furious Fire</td>\n      <td>Our Special Place</td>\n      <td>2021-05-25 22:46:00</td>\n      <td>6205</td>\n      <td>The Heavy</td>\n      <td>Our Special Place</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0386</td>\n      <td>0.2720</td>\n      <td>0.003610</td>\n      <td>0.0991</td>\n      <td>0.939</td>\n      <td>193.996</td>\n      <td>4.0</td>\n      <td>2021-05-25 21:00:00</td>\n      <td>4332</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>Make Peace and be FreePerfect Confusion</td>\n      <td>5/25/2021 4:39:00 PM</td>\n      <td>Perfect Confusion</td>\n      <td>Perfect Confusion</td>\n      <td>Make Peace and be Free</td>\n      <td>2021-05-25 22:39:00</td>\n      <td>6051</td>\n      <td>Perfect Confusion</td>\n      <td>Make Peace and be Free</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0315</td>\n      <td>0.0138</td>\n      <td>0.000017</td>\n      <td>0.0649</td>\n      <td>0.431</td>\n      <td>78.037</td>\n      <td>4.0</td>\n      <td>2021-05-25 21:00:00</td>\n      <td>4332</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50013</th>\n      <td>62902</td>\n      <td>From Me To You - Remastered 2009The Beatles</td>\n      <td>1/1/2017 10:04:00 AM</td>\n      <td>The Beatles</td>\n      <td>Past Masters (Vols. 1 &amp; 2 / Remastered)</td>\n      <td>From Me To You - Remastered 2009</td>\n      <td>2017-01-01 16:04:00</td>\n      <td>5693</td>\n      <td>The Beatles</td>\n      <td>From Me To You - Remastered 2009</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0309</td>\n      <td>0.6130</td>\n      <td>0.000000</td>\n      <td>0.2690</td>\n      <td>0.966</td>\n      <td>136.125</td>\n      <td>4.0</td>\n      <td>2017-01-01 15:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50014</th>\n      <td>62903</td>\n      <td>And I Love Her - Remastered 2009The Beatles</td>\n      <td>1/1/2017 10:01:00 AM</td>\n      <td>The Beatles</td>\n      <td>A Hard Day's Night (Remastered)</td>\n      <td>And I Love Her - Remastered 2009</td>\n      <td>2017-01-01 16:01:00</td>\n      <td>360</td>\n      <td>The Beatles</td>\n      <td>And I Love Her - Remastered 2009</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0337</td>\n      <td>0.6400</td>\n      <td>0.000000</td>\n      <td>0.0681</td>\n      <td>0.636</td>\n      <td>113.312</td>\n      <td>4.0</td>\n      <td>2017-01-01 15:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50015</th>\n      <td>62904</td>\n      <td>Ticket To Ride - Remastered 2009The Beatles</td>\n      <td>1/1/2017 9:58:00 AM</td>\n      <td>The Beatles</td>\n      <td>Help! (Remastered)</td>\n      <td>Ticket To Ride - Remastered 2009</td>\n      <td>2017-01-01 15:58:00</td>\n      <td>9715</td>\n      <td>The Beatles</td>\n      <td>Ticket To Ride - Remastered 2009</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0678</td>\n      <td>0.0457</td>\n      <td>0.000000</td>\n      <td>0.2330</td>\n      <td>0.749</td>\n      <td>123.419</td>\n      <td>4.0</td>\n      <td>2017-01-01 15:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50016</th>\n      <td>62905</td>\n      <td>Come Together - Remastered 2009The Beatles</td>\n      <td>1/1/2017 9:54:00 AM</td>\n      <td>The Beatles</td>\n      <td>Abbey Road (Remastered)</td>\n      <td>Come Together - Remastered 2009</td>\n      <td>2017-01-01 15:54:00</td>\n      <td>7425</td>\n      <td>The Beatles</td>\n      <td>Come Together - Remastered 2009</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0393</td>\n      <td>0.0302</td>\n      <td>0.248000</td>\n      <td>0.0926</td>\n      <td>0.187</td>\n      <td>165.007</td>\n      <td>4.0</td>\n      <td>2017-01-01 15:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50017</th>\n      <td>62906</td>\n      <td>Penny Lane - Remastered 2009The Beatles</td>\n      <td>1/1/2017 9:51:00 AM</td>\n      <td>The Beatles</td>\n      <td>Magical Mystery Tour (Remastered)</td>\n      <td>Penny Lane - Remastered 2009</td>\n      <td>2017-01-01 15:51:00</td>\n      <td>4401</td>\n      <td>The Beatles</td>\n      <td>Penny Lane - Remastered 2009</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0316</td>\n      <td>0.2120</td>\n      <td>0.026000</td>\n      <td>0.1360</td>\n      <td>0.490</td>\n      <td>113.038</td>\n      <td>4.0</td>\n      <td>2017-01-01 15:00:00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50018 rows Ã— 30 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkOi7VaWau9m","outputId":"885e777a-404e-4294-de1f-08d2497b2b8d","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T12:07:57.592929Z","iopub.execute_input":"2024-12-12T12:07:57.593644Z","iopub.status.idle":"2024-12-12T12:07:57.640324Z","shell.execute_reply.started":"2024-12-12T12:07:57.593610Z","shell.execute_reply":"2024-12-12T12:07:57.639457Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50018 entries, 0 to 50017\nData columns (total 30 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   index_x                    50018 non-null  int64  \n 1   SongID                     50018 non-null  object \n 2   TimeStamp_Central          50018 non-null  object \n 3   Performer_x                50018 non-null  object \n 4   Album                      47890 non-null  object \n 5   Song_x                     50018 non-null  object \n 6   TimeStamp_UTC              50018 non-null  object \n 7   index_y                    50018 non-null  int64  \n 8   Performer_y                50018 non-null  object \n 9   Song_y                     50018 non-null  object \n 10  spotify_genre              50018 non-null  object \n 11  spotify_track_id           50018 non-null  object \n 12  spotify_track_preview_url  36001 non-null  object \n 13  spotify_track_duration_ms  50018 non-null  float64\n 14  spotify_track_popularity   50018 non-null  float64\n 15  spotify_track_explicit     50018 non-null  bool   \n 16  danceability               50018 non-null  float64\n 17  energy                     50018 non-null  float64\n 18  key                        50018 non-null  float64\n 19  loudness                   50018 non-null  float64\n 20  mode                       50018 non-null  float64\n 21  speechiness                50018 non-null  float64\n 22  acousticness               50018 non-null  float64\n 23  instrumentalness           50018 non-null  float64\n 24  liveness                   50018 non-null  float64\n 25  valence                    50018 non-null  float64\n 26  tempo                      50018 non-null  float64\n 27  time_signature             50018 non-null  float64\n 28  session_3_hour             50018 non-null  object \n 29  session_id                 50018 non-null  int64  \ndtypes: bool(1), float64(14), int64(3), object(12)\nmemory usage: 11.1+ MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"test_col_name = 'mode'\n\ndf.loc[:, test_col_name]","metadata":{"id":"AUBP-uxUau9m","outputId":"7b495386-3f88-4c64-cca4-2d26ecae8f88"},"outputs":[{"data":{"text/plain":["0        1.0\n","1        0.0\n","2        1.0\n","3        1.0\n","4        1.0\n","        ... \n","50013    1.0\n","50014    0.0\n","50015    1.0\n","50016    0.0\n","50017    1.0\n","Name: mode, Length: 50018, dtype: float64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"markdown","source":"## Remove N.A.N data","metadata":{"id":"ENdbzTAEau9n"}},{"cell_type":"code","source":"# df_filtered = df[~df['danceability'].isna()]\n\n# df_filtered.info()","metadata":{"id":"YxvNRVFeau9n"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prepare Tensorflow Datasets","metadata":{"id":"LQ3vqtcvau9o"}},{"cell_type":"code","source":"import time\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.api.preprocessing.sequence import pad_sequences\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n\n\n# Feature columns (as provided)\n\nfeature_columns = [\n\n    'spotify_genre',\n\n]\n\n\n\n# Define the DataPreprocessor class\n\nclass DataPreprocessor:\n\n    def __init__(self, df, feature_columns, batch_size=16, fixed_genre_size=15, train_size=0.8):\n\n        \"\"\"\n\n        Initializes the data preprocessor with necessary parameters and preprocessing layers.\n\n\n\n        Args:\n\n            df (DataFrame): The input DataFrame containing session data.\n\n            feature_columns (list): List of feature column names.\n\n            batch_size (int): The batch size for dataset creation.\n\n            fixed_genre_size (int): The fixed size for genre vectorization.\n\n            train_size (float): Proportion of the data to use for training (between 0 and 1).\n\n        \"\"\"\n\n        self.df = df\n\n        self.feature_columns = feature_columns\n\n        self.batch_size = batch_size\n\n        self.fixed_genre_size = fixed_genre_size\n\n        self.train_size = train_size\n\n\n\n        # Split the dataset into training and testing datasets\n\n        self.train_df, self.test_df = train_test_split(self.df, train_size=self.train_size, random_state=42)\n\n\n\n        # Numeric feature preprocessing\n\n        self.numeric_data = self.df[feature_columns[1:]].apply(pd.to_numeric, errors='coerce')\n\n        self.mean_values = self.numeric_data.mean()\n\n        self.std_values = self.numeric_data.std()\n\n\n\n        # Initialize LabelEncoder for SongID and spotify_genre\n\n        self.song_id_encoder = LabelEncoder()\n\n        self.genre_encoder = LabelEncoder()\n\n\n\n        # Extract unique SongIDs and genres\n\n        unique_song_ids = self.df['SongID'].unique()\n\n        all_genres = []\n\n        for genre_str in self.df['spotify_genre']:\n\n            try:\n\n                genre_list = ast.literal_eval(genre_str)  # Safely parse the string into a list\n\n                if isinstance(genre_list, list):\n\n                    all_genres.extend(genre_list)\n\n            except Exception as e:\n\n                print(f\"Error parsing genre: {e}\")\n\n\n\n        unique_genres = list(set(all_genres))\n\n\n\n        # Fit the LabelEncoders on the data\n\n        self.song_id_encoder.fit(unique_song_ids)\n\n        self.genre_encoder.fit(unique_genres)\n\n\n\n        self.items_size = len(self.song_id_encoder.classes_)  # Number of unique SongIDs\n\n        self.genres_size = len(self.genre_encoder.classes_)\n\n\n\n        self.dataset = None\n\n\n\n    def preprocess_song_id(self, song_id):\n\n        \"\"\"\n\n        Encode the SongID using LabelEncoder.\n\n        \"\"\"\n\n        return self.song_id_encoder.transform([song_id])[0]\n\n\n\n    def clean_genre(self, value, default_value=0, dtype=tf.int32):\n\n        \"\"\"\n\n        Clean and process the 'spotify_genre' feature.\n\n        \"\"\"\n\n        if value is None or (isinstance(value, str) and not value.strip()):\n\n            return np.full((self.fixed_genre_size,), default_value, dtype=dtype.as_numpy_dtype)\n\n\n\n        try:\n\n            genre_list = eval(value) if isinstance(value, str) else value\n\n            if isinstance(genre_list, list):\n\n                genre_encoded = self.genre_encoder.transform(genre_list)\n\n            else:\n\n                genre_encoded = self.genre_encoder.transform([value])\n\n        except Exception:\n\n            genre_encoded = self.genre_encoder.transform([value])\n\n\n\n        # Pad or truncate to fixed size\n\n        return np.pad(genre_encoded, (0, max(0, self.fixed_genre_size - len(genre_encoded))),\n\n                      mode='constant')[:self.fixed_genre_size].astype(dtype.as_numpy_dtype)\n\n\n\n    def clean_numeric_feature(self, value, default_value=0.0, feature_name=\"feature\", mean=None, std=None):\n\n        \"\"\"\n\n        Clean, process, and normalize numerical features using Z-score normalization.\n\n        \"\"\"\n\n        if value is None or (isinstance(value, float) and np.isnan(value)):\n\n            return default_value\n\n\n\n        try:\n\n            value = float(value)\n\n            # Apply Z-score normalization if mean and std are provided\n\n            if mean is not None and std is not None and std != 0:\n\n                z_score_value = (value - mean) / std\n\n                return z_score_value\n\n            return value  # Return raw value if no normalization\n\n        except ValueError:\n\n            return default_value\n\n\n\n    def create_session_dataset(self, session_df):\n\n        \"\"\"\n\n        Create session dataset as a list of dictionaries for each session.\n\n        \"\"\"\n\n        session_df = session_df.sort_values(by=['session_id', 'TimeStamp_UTC'])\n\n        grouped = session_df.groupby('session_id')\n\n        sessions_data = []\n\n        for session_id, group in grouped:\n\n            session_data = group.to_dict(orient='records')\n\n            sessions_data.append(session_data)\n\n        return sessions_data\n\n\n\n    def preprocess_data(self, sessions, k=1):\n\n        \"\"\"\n\n        Preprocess session data into TensorFlow dataset with split genre and features,\n\n        filtering out sequences where the next item sequence length is not greater than 10.\n\n        \"\"\"\n\n        item_sequences = []\n\n        next_item_sequences = []\n\n        genre_sequences = []\n\n        next_genre_sequences = []\n\n        feature_sequences = []\n\n        processed_item_count = 0\n\n\n\n        for idx, session in enumerate(sessions):\n\n            # Filter the session that has length less than k\n\n            if len(session) < k:\n\n                continue\n\n            session_item_sequences = []\n\n            session_next_item_sequences = []\n\n            session_genre_sequences = []\n\n            session_next_genre_sequences= []\n\n            session_feature_sequences = []\n\n            session_id = session[0]['session_id']\n\n\n\n            for i in range(len(session) - 1):\n\n                # Process items\n\n                session_item_encoded = self.preprocess_song_id(session[i]['SongID'])\n\n                next_session_item_encoded = self.preprocess_song_id(session[i + 1]['SongID'])\n\n                session_item_sequences.append(session_item_encoded)\n\n                session_next_item_sequences.append(next_session_item_encoded)\n\n\n\n                # Process genre\n\n                genre_cleaned = self.clean_genre(session[i].get('spotify_genre', None))\n\n                next_genre_cleaned = self.clean_genre(session[i+1].get('spotify_genre', None))\n\n                session_genre_sequences.append(genre_cleaned)\n\n                session_next_genre_sequences.append(next_genre_cleaned)\n\n\n\n                # Process numerical features\n\n                numeric_features = []\n\n                for col in self.feature_columns:\n\n                    if col != 'spotify_genre':\n\n                        mean = self.mean_values.get(col, None)\n\n                        std = self.std_values.get(col, None)\n\n                        cleaned_feature = self.clean_numeric_feature(session[i].get(col, None), mean=mean, std=std)\n\n                        numeric_features.append(cleaned_feature)\n\n\n\n                session_feature_sequences.append(numeric_features)\n\n\n\n            # Filter out sessions where the next item sequence length is not greater than 10\n\n            # Extend sequences only if the next item sequence length is greater than 10\n\n            print(\"session item sequences:\", session_item_sequences)\n\n            print(\"session next item sequences:\", session_next_item_sequences)\n\n\n\n            # Filter the item that have session length less than k\n\n            item_sequences.append(session_item_sequences)\n\n            next_item_sequences.append(session_next_item_sequences)\n\n            genre_sequences.append(session_genre_sequences)\n\n            next_genre_sequences.append(session_next_genre_sequences)\n\n            feature_sequences.append(session_feature_sequences)\n\n            processed_item_count += len(session_item_sequences)\n\n\n\n            #     # print(f\"Session {idx + 1} processed with {len(session_item_sequences)} items.\")\n\n            # else:\n\n            #     print(f\"Session {idx + 1} skipped because next item sequence length is {len(session_next_item_sequences)}.\")\n\n\n\n        print(f\"Total processed items: {processed_item_count}\")\n\n\n\n        # Pad sequences\n\n        item_sequences = pad_sequences(item_sequences, padding='pre', value=0)\n\n        next_item_sequences = pad_sequences(next_item_sequences, padding='pre', value=0)\n\n        genre_sequences = pad_sequences(genre_sequences, padding='pre', value=0)\n\n        next_genre_sequences = pad_sequences(next_genre_sequences, padding='pre', value=0)\n\n        feature_sequences = pad_sequences(feature_sequences, padding='pre', dtype='float32', value=0.0)\n\n        # print(f\"item_sequences shape: {item_sequences.shape}\")\n\n        # print(f\"next_item_sequences shape: {next_item_sequences.shape}\")\n\n        # print(f\"genre_sequences shape: {genre_sequences.shape}\")\n\n        # print(f\"next_genre_sequences shape: {next_genre_sequences.shape}\")\n\n        # print(f\"feature_sequences shape: {feature_sequences.shape}\")\n\n        # print(\"item sequence padded:\", item_sequences)\n\n        # print(\"next item sequence padded:\", next_item_sequences)\n\n        # print(\"genre sequence padded:\", genre_sequences)\n\n        # print(\"next genre sequence padded:\", next_genre_sequences)\n\n        # print(\"feature sequence padded:\", feature_sequences)\n\n\n\n        # Create TensorFlow dataset\n\n        sequence_length = item_sequences.shape[1]  # Assuming all sequences have the same length after padding\n\n        print(f\"Sequence length after padding: {sequence_length}\")\n    \n        # Create TensorFlow dataset\n        dataset = tf.data.Dataset.from_tensor_slices({\n            'item': item_sequences,\n            'genre': genre_sequences,\n            'features': feature_sequences,\n            'next_item': next_item_sequences,\n            'next_genre': next_genre_sequences\n        })\n    \n        return dataset, sequence_length\n\n\n\n    def create_session_dataset_tensor(self, k=1):\n\n        \"\"\"\n\n        Main function to create session dataset as tensors and return the dataset.\n\n        \"\"\"\n\n        if self.dataset is not None:\n\n            print(\"Dataset already created\")\n\n            return\n\n\n\n        print(\"Creating session dataset\")\n\n        sessions_data = self.create_session_dataset(self.df)\n\n        dataset, sequence_length = self.preprocess_data(sessions_data, k=k)\n\n\n\n        # Shuffle and batch the training data\n\n        dataset = (\n\n            dataset.batch(self.batch_size, drop_remainder=True)\n\n                   .prefetch(buffer_size=tf.data.AUTOTUNE)\n\n        )\n\n\n\n        self.dataset = dataset\n\n        return dataset, sequence_length\n\n\n\n    def create_train_dataset(self, k=1):\n\n        \"\"\"\n\n        Main function to create session dataset as tensors and return the dataset.\n\n        \"\"\"\n\n        if self.dataset is not None:\n\n            print(\"Dataset already created\")\n\n            return\n\n\n\n        print(\"Creating session dataset\")\n\n        sessions_data = self.create_session_dataset(self.train_df)  # Use train data for training\n\n        print(\"Creating tensor dataset\")\n\n        dataset = self.preprocess_data(sessions_data, k=k)\n\n\n\n        # Shuffle and batch the training data\n\n        dataset = (\n\n            dataset.shuffle(buffer_size=1024)\n\n                   .batch(self.batch_size, drop_remainder=True)\n\n                   .prefetch(buffer_size=tf.data.AUTOTUNE)\n\n        )\n\n        return dataset\n\n\n\n    def get_test_data(self, k):\n\n        \"\"\"\n\n        Return preprocessed test dataset without shuffling.\n\n        \"\"\"\n\n        sessions_data = self.create_session_dataset(self.test_df)\n\n        dataset = self.preprocess_data(sessions_data, k)\n\n\n\n        # Batch the test data without shuffling\n\n        dataset = (\n\n            dataset.batch(self.batch_size, drop_remainder=True)\n\n                   .prefetch(buffer_size=tf.data.AUTOTUNE)\n\n        )\n\n\n\n        return dataset\n\n\n\n    def batch_timer(self, dataset):\n\n        \"\"\"\n\n        Timer function to track the time taken for batch processing.\n\n        \"\"\"\n\n        for batch in dataset:\n\n            start_time = time.time()\n\n\n\n            # Simulate processing (e.g., model training or data transformation)\n\n            end_time = time.time()\n\n            batch_time = end_time - start_time\n\n            print(f\"Batch processing time: {batch_time:.4f} seconds\")\n\n\n","metadata":{"id":"RP5P9y7yau9o","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:42:46.797122Z","iopub.execute_input":"2024-12-12T15:42:46.797451Z","iopub.status.idle":"2024-12-12T15:42:46.826696Z","shell.execute_reply.started":"2024-12-12T15:42:46.797424Z","shell.execute_reply":"2024-12-12T15:42:46.825653Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"<p style=\"font-size:36px;\">PENTING: Baca Notes Comment di setiap Sel!!!<p>","metadata":{"id":"5Ug642Mp4nKt"}},{"cell_type":"code","source":"# preprocessor = DataPreprocessor(df, feature_columns)  # <---- pakai ini untuk bener-bener ngetrain\n\npreprocessor = DataPreprocessor(df[:30], feature_columns, batch_size=2) # <------ pakai ini buat ngetes apakah bisa ditrain, bisa ekspor model, bisa import modelnya dengan lancar\n\n\n\n# Create the session dataset tensor\n\ndataset, sequence_length = preprocessor.create_session_dataset_tensor(k=3)  # k = 4 artinya mengambil sesi dengan panjang sesi item selanjutnya lebih dari 4\n\nprint(f\"Sequence Length: {sequence_length}\")\n# for batch in dataset.take(1):\n\n#     print(\"Items (SongID):\", batch['item'].numpy())\n\n#     print(\"Genre:\", batch['genre'].numpy())\n\n#     print(\"Features:\", batch['features'].numpy())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"vqP4prfnau9q","outputId":"db4e8a66-b078-460a-ff06-050e67d7cf91","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:47:45.949973Z","iopub.execute_input":"2024-12-12T15:47:45.950563Z","iopub.status.idle":"2024-12-12T15:47:45.989052Z","shell.execute_reply.started":"2024-12-12T15:47:45.950519Z","shell.execute_reply":"2024-12-12T15:47:45.988229Z"}},"outputs":[{"name":"stdout","text":"Creating session dataset\nsession item sequences: [21, 8, 2, 7, 18, 5, 23, 17, 6, 19, 12, 13, 16, 3]\nsession next item sequences: [8, 2, 7, 18, 5, 23, 17, 6, 19, 12, 13, 16, 3, 2]\nsession item sequences: [20, 0, 4, 22, 9, 19, 13]\nsession next item sequences: [0, 4, 22, 9, 19, 13, 17]\nsession item sequences: [17, 15, 10, 11, 14, 1]\nsession next item sequences: [15, 10, 11, 14, 1, 24]\nTotal processed items: 27\nSequence length after padding: 14\nSequence Length: 14\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"test_dataset = preprocessor.get_test_data(k=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nPLPszcfaHv","outputId":"d0688b74-7cfa-461b-f2b0-62253af0b9c6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(dataset))\n\nfor batch in dataset.take(1):\n\n    print(\"Items (SongID):\", batch['item'].numpy())\n\n    print(\"Genre:\", batch['genre'].numpy())\n\n    print(\"Features:\", batch['features'].numpy())\n\n    print(\"Next Items (Next SongID):\", batch['next_item'].numpy())\n\n    print(\"Next Genre:\", batch['next_genre'].numpy())\n\n    # print(batch.type())\n\n\n\nprint(dataset)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gaFqUvobau9r","outputId":"737d98d4-0530-411a-c356-35e294c71045","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:47:54.089678Z","iopub.execute_input":"2024-12-12T15:47:54.090508Z","iopub.status.idle":"2024-12-12T15:47:54.106785Z","shell.execute_reply.started":"2024-12-12T15:47:54.090469Z","shell.execute_reply":"2024-12-12T15:47:54.106021Z"}},"outputs":[{"name":"stdout","text":"1\nItems (SongID): [[21  8  2  7 18  5 23 17  6 19 12 13 16  3]\n [ 0  0  0  0  0  0  0 20  0  4 22  9 19 13]]\nGenre: [[[27 36 37 41 47  0  0  0  0  0  0  0  0  0  0]\n  [27 36 37 41 47  0  0  0  0  0  0  0  0  0  0]\n  [ 0  8 19 24 47 52  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 24 43 47 52 56  0  0  0  0  0  0  0]\n  [ 0  3  8 24 43 47 52 56  0  0  0  0  0  0  0]\n  [27 36 37 41 47  0  0  0  0  0  0  0  0  0  0]\n  [35  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  8 14 20 24 40 47 50 51 52  0  0  0  0  0]\n  [ 6  8 47 48 49 53  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 43 44 47 56  0  0  0  0  0  0  0  0]\n  [ 0  3  8 19 23 43 44 47 56  0  0  0  0  0  0]\n  [ 1  7 16 34 41 46 59  0  0  0  0  0  0  0  0]\n  [ 2 17 21 26 27 47  0  0  0  0  0  0  0  0  0]\n  [ 0  4 11 24 30 31 32 47 52  0  0  0  0  0  0]]\n\n [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  6  8 18 19 25 47 54  0  0  0  0  0  0  0]\n  [ 0  3  8 14 19 24 43 47 52 56  0  0  0  0  0]\n  [ 0  3  8 43 44 47 56  0  0  0  0  0  0  0  0]\n  [ 0  8 24 47 52 60  0  0  0  0  0  0  0  0  0]\n  [27 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 43 44 47 56  0  0  0  0  0  0  0  0]\n  [ 1  7 16 34 41 46 59  0  0  0  0  0  0  0  0]]]\nFeatures: []\nNext Items (Next SongID): [[ 8  2  7 18  5 23 17  6 19 12 13 16  3  2]\n [ 0  0  0  0  0  0  0  0  4 22  9 19 13 17]]\nNext Genre: [[[27 36 37 41 47  0  0  0  0  0  0  0  0  0  0]\n  [ 0  8 19 24 47 52  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 24 43 47 52 56  0  0  0  0  0  0  0]\n  [ 0  3  8 24 43 47 52 56  0  0  0  0  0  0  0]\n  [27 36 37 41 47  0  0  0  0  0  0  0  0  0  0]\n  [35  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  8 14 20 24 40 47 50 51 52  0  0  0  0  0]\n  [ 6  8 47 48 49 53  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 43 44 47 56  0  0  0  0  0  0  0  0]\n  [ 0  3  8 19 23 43 44 47 56  0  0  0  0  0  0]\n  [ 1  7 16 34 41 46 59  0  0  0  0  0  0  0  0]\n  [ 2 17 21 26 27 47  0  0  0  0  0  0  0  0  0]\n  [ 0  4 11 24 30 31 32 47 52  0  0  0  0  0  0]\n  [ 0  8 19 24 47 52  0  0  0  0  0  0  0  0  0]]\n\n [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 14 19 24 43 47 52 56  0  0  0  0  0]\n  [ 0  3  8 43 44 47 56  0  0  0  0  0  0  0  0]\n  [ 0  8 24 47 52 60  0  0  0  0  0  0  0  0  0]\n  [27 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n  [ 0  3  8 43 44 47 56  0  0  0  0  0  0  0  0]\n  [ 1  7 16 34 41 46 59  0  0  0  0  0  0  0  0]\n  [ 0  8 14 20 24 40 47 50 51 52  0  0  0  0  0]]]\n<_PrefetchDataset element_spec={'item': TensorSpec(shape=(2, 14), dtype=tf.int32, name=None), 'genre': TensorSpec(shape=(2, 14, 15), dtype=tf.int32, name=None), 'features': TensorSpec(shape=(2, 14, 0), dtype=tf.float32, name=None), 'next_item': TensorSpec(shape=(2, 14), dtype=tf.int32, name=None), 'next_genre': TensorSpec(shape=(2, 14, 15), dtype=tf.int32, name=None)}>\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"DATASET_SIZE = 37728\ntrain_size = int(0.8*DATASET_SIZE)\ntrain_dataset = dataset.take(train_size)\nval_dataset = dataset.take(train_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:59:03.983080Z","iopub.execute_input":"2024-12-11T15:59:03.983415Z","iopub.status.idle":"2024-12-11T15:59:03.991750Z","shell.execute_reply.started":"2024-12-11T15:59:03.983386Z","shell.execute_reply":"2024-12-11T15:59:03.991106Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"for batch in train_dataset.take(1):\n    print(\"Items (SongID):\", batch['item'].numpy())\n\n    print(\"Genre:\", batch['genre'].numpy())\n\n    print(\"Features:\", batch['features'].numpy())\n\n    print(\"Next Items (Next SongID):\", batch['next_item'].numpy())\n\nfor batch in val_dataset.take(1):\n    print(\"Items (SongID):\", batch['item'].numpy())\n\n    print(\"Genre:\", batch['genre'].numpy())\n\n    print(\"Features:\", batch['features'].numpy())\n\n    print(\"Next Items (Next SongID):\", batch['next_item'].numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T17:49:59.974095Z","iopub.execute_input":"2024-12-11T17:49:59.974435Z","iopub.status.idle":"2024-12-11T17:50:00.006028Z","shell.execute_reply.started":"2024-12-11T17:49:59.974410Z","shell.execute_reply":"2024-12-11T17:50:00.005143Z"}},"outputs":[{"name":"stdout","text":"Items (SongID): [[    0     0     0 ...  8655   354  6331]\n [    0     0     0 ...  2245  4268 10534]\n [    0     0     0 ...  3905  3362  8022]\n ...\n [    0     0     0 ...   332  4091  2570]\n [    0     0     0 ...  1872   674   493]\n [    0     0     0 ...  2646  8927  7362]]\nGenre: [[[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 157  711  934 ...    0    0    0]\n  [ 157  711  934 ...    0    0    0]\n  [ 157  711  934 ...    0    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [  15   52  255 ... 1031    0    0]\n  [  15   52  157 ...  931  971  980]\n  [   9   15  255 ... 1195    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 336  560  724 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [ 320  474  783 ...    0    0    0]]\n\n ...\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [  15  157  255 ...    0    0    0]\n  [  15  157  255 ...    0    0    0]\n  [  15  157  255 ...    0    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 769    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 959    0    0 ...    0    0    0]\n  [  65  336  560 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]]]\nFeatures: []\nNext Items (Next SongID): [[    0     0     0 ...   354  6331  1984]\n [    0     0     0 ...  4268 10534  4906]\n [    0     0     0 ...  3362  8022  2635]\n ...\n [    0     0     0 ...  4091  2570  5020]\n [    0     0     0 ...   674   493  1493]\n [    0     0     0 ...  8927  7362  8602]]\nItems (SongID): [[    0     0     0 ...  8655   354  6331]\n [    0     0     0 ...  2245  4268 10534]\n [    0     0     0 ...  3905  3362  8022]\n ...\n [    0     0     0 ...   332  4091  2570]\n [    0     0     0 ...  1872   674   493]\n [    0     0     0 ...  2646  8927  7362]]\nGenre: [[[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 157  711  934 ...    0    0    0]\n  [ 157  711  934 ...    0    0    0]\n  [ 157  711  934 ...    0    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [  15   52  255 ... 1031    0    0]\n  [  15   52  157 ...  931  971  980]\n  [   9   15  255 ... 1195    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 336  560  724 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [ 320  474  783 ...    0    0    0]]\n\n ...\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [  15  157  255 ...    0    0    0]\n  [  15  157  255 ...    0    0    0]\n  [  15  157  255 ...    0    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 769    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]]\n\n [[   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]\n  ...\n  [ 959    0    0 ...    0    0    0]\n  [  65  336  560 ...    0    0    0]\n  [   0    0    0 ...    0    0    0]]]\nFeatures: []\nNext Items (Next SongID): [[    0     0     0 ...   354  6331  1984]\n [    0     0     0 ...  4268 10534  4906]\n [    0     0     0 ...  3362  8022  2635]\n ...\n [    0     0     0 ...  4091  2570  5020]\n [    0     0     0 ...   674   493  1493]\n [    0     0     0 ...  8927  7362  8602]]\n","output_type":"stream"}],"execution_count":183},{"cell_type":"code","source":"for batch in test_dataset.take(1):\n\n    print(\"Items (SongID):\", batch['item'].numpy())\n\n    print(\"Genre:\", batch['genre'].numpy())\n\n    print(\"Features:\", batch['features'].numpy())\n\n    print(\"Next Items (Next SongID):\", batch['next_item'].numpy())","metadata":{"id":"MalfdduKbjlB","colab":{"base_uri":"https://localhost:8080/","height":219},"outputId":"462296f9-acfe-441d-ba46-a4e7f6e13d3a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Model class","metadata":{"id":"Fo1s8zV6au9r"}},{"cell_type":"code","source":"@keras.saving.register_keras_serializable(package=\"gru4rec_with_attention\")\nclass ItemEmbedding(Layer):\n\n    def __init__(self, num_items, item_embed_dim, **kwargs):\n\n        super(ItemEmbedding, self).__init__(**kwargs)\n\n\n\n        self.item_embedding = Embedding(input_dim=num_items, output_dim=item_embed_dim, mask_zero=True)\n\n\n\n    def call(self, items):\n\n        # Embed items\n\n        items_embedded = self.item_embedding(items)\n\n        return items_embedded\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"num_items\": self.num_items,\n            \"item_embed_dim\": self.item_embed_dim\n        })\n        return config\n\n\n@keras.saving.register_keras_serializable(package=\"gru4rec_with_attention\")\nclass GRU4REC(Model):\n\n    def __init__(self, rnn_params, genre_embed_dim, item_embed_dim, ffn1_units, feature_dense_units,  items_size, genres_size, *args, **kwargs):\n\n        super(GRU4REC, self).__init__(*args, **kwargs)\n\n        self.rnn_params = rnn_params\n        self.genre_embed_dim = genre_embed_dim\n        self.item_embed_dim = item_embed_dim\n        self.ffn1_units = ffn1_units\n        self.feature_dense_units = feature_dense_units\n        self.items_size = items_size\n        self.genres_size = genres_size\n        self.input_shape = None\n\n        print(f\"items size: {items_size}\")\n\n        print(f\"genres size: {genres_size}\")\n        self.embedding = Embedding(input_dim=items_size, output_dim=item_embed_dim, mask_zero=True)\n\n        \n\n        # Genre embedding (only for genre, which is categorical and a string)\n\n        self.genre_embedding = Embedding(input_dim=genres_size, output_dim=genre_embed_dim, mask_zero=True, name='genre_embedding')\n\n\n\n        # RNN layers\n\n        self.rnn_layers = []\n\n        self.rnn_layers.append(GRU(**rnn_params[0], return_sequences=True))\n\n        for i in range(1, len(rnn_params) - 1):\n\n            self.rnn_layers.append(GRU(**rnn_params[i], return_sequences=True))\n\n        self.rnn_layers.append(GRU(**rnn_params[-1], return_sequences=True))\n\n\n\n        self.concat = Concatenate(axis=-1, name='concat_1')\n\n        self.batch_norm = BatchNormalization(name='batchnorm')\n\n\n\n        # Dropout layer\n\n        self.dropout = Dropout(0.2, name='dropout')\n\n\n\n        # Feed-forward layers\n\n        self.feature_dense = Dense(feature_dense_units, activation='relu', name='feature_dense')  # Dense layer for features (if required)\n\n        self.ffn1 = Dense(ffn1_units, name='ffn_1')\n\n        self.activation1 = LeakyReLU(negative_slope=0.2, name='freaky_relu')\n\n        self.item_output = Dense(items_size, name='item_output')\n\n        # self.genre_output = Dense(preprocessed_data.genres_size, activation='softmax', name='genre_output')\n\n\n\n        self.attention = Attention(use_scale=False, dropout=0.2, name='attention')\n\n\n\n    def call(self, inputs, training=False):\n\n        \"\"\"\n\n        Forward pass for the GRU4REC model.\n\n        :param inputs: Tuple (item_sequences, item_features, item_genres)\n\n        :param training: Boolean indicating if the model is in training mode\n\n        \"\"\"\n\n        item_sequences, item_features, item_genres = inputs\n\n        # Update input shape dynamically\n        if self.input_shape is None:\n            # Set the input shape based on the first batch of inputs\n            self.input_shape = item_sequences.shape\n\n        encoding_padding_mask = tf.math.logical_not(tf.math.equal(item_sequences, 0))\n\n\n\n        # print(\"Item Sequence Shape:\", item_sequences.shape)\n\n        # print(\"Item Genres Shape:\", item_genres.shape)\n\n        # Embed items\n\n        item_embedded = self.embedding(item_sequences)\n\n        item_embedded = tf.expand_dims(item_embedded, axis=2)\n\n        # Genre embedding\n\n        genre_embedded = self.genre_embedding(item_genres)\n\n\n\n        # print(\"Item Embedded Shape:\", item_embedded.shape)\n\n        # print(\"Genre Embedded Shape:\", genre_embedded.shape)\n\n        genre_embedded = tf.reduce_mean(genre_embedded, axis=2)\n\n        genre_embedded = tf.expand_dims(genre_embedded, axis=2)\n\n\n\n        # Feature transformation (features are passed directly as floats, so no embedding is needed)\n\n        # feature_transformed = self.feature_dense(item_features)\n\n        # feature_transformed = tf.expand_dims(feature_transformed, axis=1)\n\n\n\n        # combined_input = tf.concat([item_embedded, feature_transformed, genre_embedded], axis=-1)\n\n        combined_input = tf.concat([item_embedded, genre_embedded], axis=-1)\n\n        combined_input = self.batch_norm(combined_input)\n\n        # print(\"Combined input shape:\",combined_input.shape)\n\n        # Pass through RNN layers\n        combined_input = tf.reduce_mean(combined_input, axis=-2)\n\n        # print(\"Reduced input shape:\", combined_input.shape)\n\n        x = combined_input\n\n        x = self.rnn_layers[0](x)\n\n        x = self.dropout(x, training=training)\n\n        for i in range(1, len(self.rnn_layers)):\n\n            x = self.concat([combined_input, x])  # Concatenate item embeddings with RNN outputs\n\n            x = self.rnn_layers[i](x)\n\n            x = self.dropout(x, training=training)\n\n\n\n        # x = self.batch_norm(x)\n\n\n\n        # # Give attention\n\n        # encodding_padding_mask = tf.expand_dims(encoding_padding_mask, axis=1)\n\n        # # x = tf.expand_dims(x, axis=1)\n        # print(f\"Shape before attention: {x.shape}\")\n\n        # x = self.attention(inputs=[x,x], mask=[encodding_padding_mask, encodding_padding_mask], use_causal_mask=True)\n\n\n\n        # Feed-forward layers\n\n        # print(f\"Shape before squeeze: {x.shape}\")\n\n        # x = tf.squeeze(x, axis=1)\n\n        # print(f\"Shape before softmax: {x.shape}\")\n\n        x = self.ffn1(x)\n\n        x = self.dropout(x, training=training)\n\n        x = self.activation1(x)\n\n        # print(f\"Shape after activation: {x.shape}\")\n\n        item_logits = self.item_output(x)  # Item prediction\n\n        # print(f\"Output shape: {item_logits.shape}\")\n\n\n\n        return item_logits\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"rnn_params\": self.rnn_params,\n            \"genre_embed_dim\": self.genre_embed_dim,\n            \"item_embed_dim\": self.item_embed_dim,\n            \"ffn1_units\": self.ffn1_units,\n            \"feature_dense_units\": self.feature_dense_units,\n            \"items_size\": self.items_size,\n            \"genres_size\": self.genres_size,\n        })\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)","metadata":{"id":"urRmM_jCau9r","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:43:19.926344Z","iopub.execute_input":"2024-12-12T15:43:19.926709Z","iopub.status.idle":"2024-12-12T15:43:19.944391Z","shell.execute_reply.started":"2024-12-12T15:43:19.926677Z","shell.execute_reply":"2024-12-12T15:43:19.943534Z"},"_kg_hide-input":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def build_gru4rec_model(rnn_params, genre_embed_dim, item_embed_dim, ffn1_units, feature_dense_units,  items_size, genres_size, seq_length, loss_fn, optimizer):\n    items_sequence = keras.api.Input(shape=[seq_length], name=\"item_sequence\")\n    genres_sequence = keras.api.Input(shape=[seq_length, None], name=\"genre_sequence\")\n    \n    # encoding_padding_mask = tf.math.logical_not(tf.math.equal(items_sequence, 0))\n    \n    item_embedded = Embedding(input_dim=items_size, output_dim=item_embed_dim, mask_zero=True, name=\"item_embedding\")(items_sequence)\n    item_embedded = Lambda(lambda x: tf.expand_dims(x, axis=2), output_shape=(seq_length, 1, item_embed_dim))(item_embedded)\n\n    # Genre embedding\n    genre_embedded = Embedding(input_dim=genres_size, output_dim=genre_embed_dim, mask_zero=True, name='genre_embedding')(genres_sequence)\n\n    # print(\"Item Embedded Shape:\", item_embedded.shape)\n    # print(\"Genre Embedded Shape:\", genre_embedded.shape)\n    genre_embedded = Lambda(lambda x:tf.reduce_mean(x, axis=2),output_shape=(seq_length, genre_embed_dim))(genre_embedded)\n    genre_embedded = Lambda(lambda x:tf.expand_dims(x, axis=2),output_shape=(seq_length, 1, genre_embed_dim))(genre_embedded)\n    \n    combined_input = Concatenate(axis=-1)([item_embedded, genre_embedded])\n\n    combined_input = BatchNormalization(name='batchnorm')(combined_input)\n\n    # print(\"Combined input shape:\",combined_input.shape)\n\n    # Pass through RNN layers\n    combined_input = Lambda(lambda x:tf.reduce_mean(x, axis=-2), output_shape=(seq_length, genre_embed_dim + item_embed_dim))(combined_input)\n\n    x = combined_input\n    x = GRU(**rnn_params[0], return_sequences=True, name='gru_0')(x)\n    x = Dropout(0.2, name='dropout_0')(x)\n    for i in range(1, len(rnn_params)-1):\n        x = Concatenate(axis=-1)([combined_input, x])\n        x = GRU(**rnn_params[i], return_sequences=True, name=f'gru_{i}')(x)\n        x = Dropout(0.2, name=f'dropout_{i}')(x)\n\n    # Final GRU layer without return_sequences\n    x = GRU(**rnn_params[-1], return_sequences=True, name=f'gru_{len(rnn_params) - 1}')(x)\n    x = Dropout(0.2, name='dropout_final')(x)\n\n    # Final Feed-forward layer\n    x = Dense(ffn1_units, activation='relu', name='feature_dense')(x)\n    x = Dropout(0.2, name='feature_dropout')(x)\n\n    # Output layer for item predictions\n    output = Dense(items_size, activation='linear', name='output_layer')(x)\n\n    # Build the model\n    model = keras.Model(inputs=[items_sequence, genres_sequence], outputs=output, name='GRU4Rec_Model')\n\n    model.compile(\n        loss=loss_fn,\n        optimizer = optimizer\n    )\n\n    return model\n\ndef train_model(model, train_dataset,epochs, val_dataset=None):\n    # train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n    def preprocess(data):\n        return {\n            \"item_sequence\": data[\"item\"], \n            \"genre_sequence\": data[\"genre\"]\n        }, data[\"next_item\"]  # Assuming \"next_item\" is the target\n\n    train_dataset = train_dataset.map(preprocess)\n    # val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n        tf.distribute.experimental.CollectiveCommunication.AUTO)\n    \n    with mirrored_strategy.scope():\n        mirrored_model = model\n\n    history = mirrored_model.fit(train_dataset,\n                                 steps_per_epoch=5,\n                                 epochs=epochs, verbose=2)\n\n    return mirrored_model, history\n    \n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_object_ = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n                                                                 reduction='none')\n    loss_ = loss_object_(real, pred)\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    \n    return tf.reduce_mean(loss_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T12:56:27.036452Z","iopub.execute_input":"2024-12-12T12:56:27.036878Z","iopub.status.idle":"2024-12-12T12:56:27.057554Z","shell.execute_reply.started":"2024-12-12T12:56:27.036839Z","shell.execute_reply":"2024-12-12T12:56:27.056612Z"}},"outputs":[],"execution_count":81},{"cell_type":"markdown","source":"## Training Loop","metadata":{"id":"k0qU_Hpsau9s"}},{"cell_type":"code","source":"import keras.api\n\nfrom keras.api.metrics import Recall\n\n\n\n@keras.saving.register_keras_serializable(package=\"gru4rec_with_attention\")\n\nclass RecallAtK(tf.keras.metrics.Metric):\n\n    def __init__(self, k=10, name=\"recall_at_k\", **kwargs):\n\n        super(RecallAtK, self).__init__(name=name, **kwargs)\n\n        self.k = k\n\n        self.recall_at_k = Recall(top_k=self.k)\n\n\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n\n        \"\"\"\n\n        Update the state of the metric.\n\n        \"\"\"\n\n        # Since y_true is a list of true items and y_pred are the predicted scores,\n\n        # we need to calculate recall for top-k predicted items\n\n        y_true = tf.cast(y_true, tf.int32)\n\n\n\n        # Calculate the top-k predicted items\n\n        top_k_preds = tf.argsort(y_pred, axis=-1, direction='DESCENDING')[:, :self.k]\n\n\n\n        # Calculate recall by comparing true labels with the top-k predictions\n\n        recall = tf.reduce_mean(tf.cast(tf.equal(y_true, top_k_preds), tf.float32), axis=-1)\n\n        return recall\n\n\n\n    def result(self):\n\n        return self.recall_at_k.result()\n\n\n\n    def reset_state(self):\n\n        self.recall_at_k.reset_state()\n\n\n\n@keras.saving.register_keras_serializable(package=\"gru4rec_with_attention\")\n\nclass GRU4RECLoss(tf.keras.losses.Loss):\n\n    def __init__(self, item_loss_weight=1.0, genre_loss_weight=1.0, name=\"gru4rec_loss\"):\n\n        super(GRU4RECLoss, self).__init__(name=name)\n\n        self.item_loss_weight = item_loss_weight\n\n        self.genre_loss_weight = genre_loss_weight\n\n        self.categorical_crossentropy = keras.api.losses.CategoricalCrossentropy()\n\n        self.sparse_categorical_crossentropy = keras.api.losses.SparseCategoricalCrossentropy()\n\n        self.binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n\n\n\n    def sparse_to_multi_hot(self, true_genres, num_genres):\n\n        \"\"\"\n\n        Converts sparse label encoded genres into multi-hot encoded vectors.\n\n\n\n        :param true_genres: Tensor of shape (batch_size, num_labels) with sparse integer labels\n\n        :param num_genres: Total number of genres (the size of the multi-hot vector)\n\n        :return: Multi-hot encoded tensor of shape (batch_size, num_genres)\n\n        \"\"\"\n\n        ## Create a tensor of zeros with shape (batch_size, num_genres)\n\n        batch_size = tf.shape(true_genres)[0]\n\n        multi_hot = tf.zeros((batch_size, num_genres), dtype=tf.float32)\n\n\n\n        # Flatten the batch for indexing\n\n        indices = tf.reshape(true_genres, [-1])  # Flatten true_genres to a 1D tensor\n\n        updates = tf.ones_like(indices, dtype=tf.float32)  # Create a 1D tensor of ones\n\n        batch_indices = tf.repeat(tf.range(batch_size), tf.shape(true_genres)[1])  # Batch indices for each label\n\n\n\n        # Combine batch and label indices\n\n        scatter_indices = tf.stack([batch_indices, indices], axis=1)\n\n\n\n        # Update the multi-hot tensor\n\n        multi_hot = tf.tensor_scatter_nd_update(multi_hot, scatter_indices, updates)\n\n\n\n        return multi_hot\n\n\n\n    def call(self, y_true, y_pred):\n\n        \"\"\"\n\n        Compute the total loss.\n\n        :param y_true: A tuple (true_items, true_genres)\n\n        :param y_pred: A tuple (predicted_items, predicted_genres)\n\n        \"\"\"\n\n        true_items, true_genres = y_true\n\n        pred_items, pred_genres = y_pred\n\n\n\n        # Calculate item loss\n\n        item_loss = self.sparse_categorical_crossentropy(true_items, pred_items)\n\n\n\n        true_genres = tf.cast(true_genres, tf.int32)\n\n        num_genres = pred_genres.shape[1]\n\n\n\n        true_genres_multi_hot = self.sparse_to_multi_hot(true_genres, num_genres)\n\n\n\n\n\n        # Calculate genre loss\n\n        genre_loss = self.binary_crossentropy(true_genres_multi_hot, pred_genres)\n\n\n\n        total_loss = self.item_loss_weight * item_loss + self.genre_loss_weight * genre_loss\n\n        return total_loss\n\n\n\n# @tf.function\n\ndef train_step(batch, loss_fn, model, optimizer):\n\n    with tf.GradientTape() as tape:\n\n        item_logits = model((batch['item'], batch['features'], batch['genre']), training=True)\n\n        loss = loss_fn(batch['next_item'], item_logits)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    return loss\n\n\n\ndef train_gru4rec(model, train_dataset, optimizer, epochs, k, val_dataset=None, loss_fn = keras.api.losses.SparseCategoricalCrossentropy(from_logits=True)):\n\n    # metric = tf.keras.metrics.TopKCategoricalAccuracy(k=k)\n\n\n    loss_history = []\n\n    val_loss_history = []\n\n    val_metric_history = []\n\n    metric_history = []\n\n    for epoch in range(epochs):\n\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n\n        epoch_loss = 0.0\n\n\n\n        for step, batch in enumerate(train_dataset):\n\n            loss = train_step(batch, loss_fn, model, optimizer)\n\n            if loss is None:\n\n              print(f\"Warning: train_step returned None at step {step}\")\n\n              continue\n\n            epoch_loss += loss.numpy()\n\n\n\n            # Update metric\n\n            # metric.update_state(batch['next_item'], logits)\n\n\n\n        print(f\"Training Loss: {epoch_loss / (step + 1):.4f}\")\n\n        loss_history.append(epoch_loss / (step + 1))\n\n        # metric_history.append(metric.result().numpy())\n\n        # metric.reset_state()\n\n\n\n        if val_dataset:\n\n            val_loss = 0.0\n\n            for step, batch in enumerate(val_dataset):\n\n                item_logits, genre_logits = model((batch['item'], batch['features'], batch['genre']), training=False)\n\n                val_loss += loss_fn((batch['next_item'], batch['next_genre']), (item_logits, genre_logits)).numpy()\n\n            print(f\"Validation Loss: {val_loss / (step + 1):.4f}\")\n\n            val_loss_history.append(val_loss / (step + 1))\n\n    return {\n\n        'loss_history': loss_history,\n\n        'metric_history': metric_history,\n\n        'val_loss_history': val_loss_history,\n\n        'val_metric_history': val_metric_history\n\n    }\n\n\n","metadata":{"id":"2_6LBqBlau9s","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:43:30.290818Z","iopub.execute_input":"2024-12-12T15:43:30.291165Z","iopub.status.idle":"2024-12-12T15:43:30.364792Z","shell.execute_reply.started":"2024-12-12T15:43:30.291132Z","shell.execute_reply":"2024-12-12T15:43:30.363953Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Run with strategy","metadata":{"id":"8vN2c_coYWs2"}},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\n\nitems_size = preprocessor.items_size\ngenres_size = preprocessor.genres_size\n\nwith strategy.scope():\n\n    model = GRU4REC(\n\n        rnn_params=[\n\n          {\"units\": 128},\n\n          {\"units\": 128},\n\n          {\"units\": 64}\n\n        ],\n\n        item_embed_dim=32,\n\n        genre_embed_dim=32,\n\n        ffn1_units=256,\n\n        feature_dense_units=16,\n\n        items_size=items_size,\n        genres_size=genres_size\n\n    )\n\n    optimizer = keras.api.optimizers.Adam(learning_rate=0.001)\n\n    loss_fn = keras.api.losses.SparseCategoricalCrossentropy()","metadata":{"id":"Qd0w08zYC9oJ","outputId":"324f1cc5-8b00-49d9-b775-0d5612ebebb5","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:48:03.822305Z","iopub.execute_input":"2024-12-12T15:48:03.822680Z","iopub.status.idle":"2024-12-12T15:48:03.869495Z","shell.execute_reply.started":"2024-12-12T15:48:03.822647Z","shell.execute_reply":"2024-12-12T15:48:03.868581Z"}},"outputs":[{"name":"stdout","text":"items size: 25\ngenres size: 61\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"\n@tf.function\n\ndef distributed_train_step(batch, loss_fn, model, optimizer):\n\n    def step_fn(batch):\n\n      with tf.GradientTape() as tape:\n\n          item_logits = model((batch['item'], batch['features'], batch['genre']), training=True)\n\n          loss = loss_fn(batch['next_item'], item_logits)\n\n      gradients = tape.gradient(loss, model.trainable_variables)\n\n      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n      return loss\n\n\n\n    per_replica_losses = strategy.run(step_fn, args=(batch,))\n\n    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n\n\n\n@tf.function\n\ndef distributed_val_step(batch, loss_fn, model):\n\n    def step_fn(batch):\n\n        item_logits, genre_logits = model((batch['item'], batch['features'], batch['genre']), training=False)\n\n        loss = loss_fn((batch['next_item'], batch['next_genre']), (item_logits, genre_logits))\n\n        return loss\n\n\n\n    per_replica_losses = strategy.run(step_fn, args=(batch,))\n\n    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n\n\n\ndef train_gru4rec_with_strategy(model, train_dataset, optimizer, epochs, k, loss_fn, val_dataset=None, early_stopping=None):\n\n    loss_history = []\n\n    val_loss_history = []\n\n    val_metric_history = []\n\n    metric_history = []\n\n    for epoch in range(epochs):\n\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n\n        epoch_loss = 0.0\n\n        for step, batch in enumerate(train_dataset):\n\n            loss = distributed_train_step(batch, loss_fn, model, optimizer)\n\n            if loss is None:\n\n              print(f\"Warning: train_step returned None at step {step}\")\n\n              continue\n\n            epoch_loss += loss.numpy()\n\n\n\n        print(f\"Training Loss: {epoch_loss / (step + 1):.4f}\")\n\n        loss_history.append(epoch_loss / (step + 1))\n\n        if val_dataset:\n\n            val_loss = 0.0\n\n            for step, batch in enumerate(val_dataset):\n\n                val_loss += distributed_val_step(batch, loss_fn, model).numpy()\n\n            print(f\"Validation Loss: {val_loss / (step + 1):.4f}\")\n\n            val_loss_history.append(val_loss / (step + 1))\n\n\n\n    return {\n\n        'loss_history': loss_history,\n\n        'metric_history': metric_history,\n\n        'val_loss_history': val_loss_history,\n\n        'val_metric_history': val_metric_history\n\n    }\n","metadata":{"id":"mfG75HwPYYI8","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:48:12.682250Z","iopub.execute_input":"2024-12-12T15:48:12.682930Z","iopub.status.idle":"2024-12-12T15:48:12.693363Z","shell.execute_reply.started":"2024-12-12T15:48:12.682895Z","shell.execute_reply":"2024-12-12T15:48:12.692525Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Train with distributed Training","metadata":{"id":"nfj1AZ1KaFxg"}},{"cell_type":"code","source":"from keras.api.callbacks import EarlyStopping\nimport time\n\n# from keras.api.optimizers import Adam\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_object_ = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n                                                                 reduction='none')\n    loss_ = loss_object_(real, pred)\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    \n    return tf.reduce_mean(loss_)\n\nstart_time = time.time()\n# history = train_gru4rec_with_strategy(model, train_dataset.take(10), optimizer, epochs=50, loss_fn=loss_function, k=8)\nhistory = train_gru4rec_with_strategy(model, dataset, optimizer, epochs=100, loss_fn=loss_function, k=8)\nprint(\"Execution time: {}\".format(time.time() - start_time))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Q_1BbWZIaLfQ","outputId":"de3bebd4-74ea-4845-d6db-3c0bc2618964","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:48:20.132836Z","iopub.execute_input":"2024-12-12T15:48:20.133285Z","iopub.status.idle":"2024-12-12T15:48:33.859606Z","shell.execute_reply.started":"2024-12-12T15:48:20.133251Z","shell.execute_reply":"2024-12-12T15:48:33.858495Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'gru4rec_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 4.6728\nEpoch 2/100\nTraining Loss: 4.5176\nEpoch 3/100\nTraining Loss: 4.3528\nEpoch 4/100\nTraining Loss: 4.2035\nEpoch 5/100\nTraining Loss: 4.0869\nEpoch 6/100\nTraining Loss: 3.9506\nEpoch 7/100\nTraining Loss: 3.8323\nEpoch 8/100\nTraining Loss: 3.6477\nEpoch 9/100\nTraining Loss: 3.4866\nEpoch 10/100\nTraining Loss: 3.3359\nEpoch 11/100\nTraining Loss: 3.2807\nEpoch 12/100\nTraining Loss: 3.0899\nEpoch 13/100\nTraining Loss: 2.7948\nEpoch 14/100\nTraining Loss: 2.7150\nEpoch 15/100\nTraining Loss: 2.5696\nEpoch 16/100\nTraining Loss: 2.6579\nEpoch 17/100\nTraining Loss: 2.4985\nEpoch 18/100\nTraining Loss: 2.1852\nEpoch 19/100\nTraining Loss: 2.0065\nEpoch 20/100\nTraining Loss: 1.8871\nEpoch 21/100\nTraining Loss: 1.8436\nEpoch 22/100\nTraining Loss: 1.8419\nEpoch 23/100\nTraining Loss: 1.5899\nEpoch 24/100\nTraining Loss: 1.5263\nEpoch 25/100\nTraining Loss: 1.3762\nEpoch 26/100\nTraining Loss: 1.3478\nEpoch 27/100\nTraining Loss: 1.3177\nEpoch 28/100\nTraining Loss: 1.2197\nEpoch 29/100\nTraining Loss: 1.1740\nEpoch 30/100\nTraining Loss: 1.0168\nEpoch 31/100\nTraining Loss: 1.0818\nEpoch 32/100\nTraining Loss: 0.9086\nEpoch 33/100\nTraining Loss: 0.9686\nEpoch 34/100\nTraining Loss: 0.7863\nEpoch 35/100\nTraining Loss: 0.6901\nEpoch 36/100\nTraining Loss: 0.6923\nEpoch 37/100\nTraining Loss: 0.6856\nEpoch 38/100\nTraining Loss: 0.5869\nEpoch 39/100\nTraining Loss: 0.5957\nEpoch 40/100\nTraining Loss: 0.4891\nEpoch 41/100\nTraining Loss: 0.5637\nEpoch 42/100\nTraining Loss: 0.5035\nEpoch 43/100\nTraining Loss: 0.3864\nEpoch 44/100\nTraining Loss: 0.3712\nEpoch 45/100\nTraining Loss: 0.3239\nEpoch 46/100\nTraining Loss: 0.3199\nEpoch 47/100\nTraining Loss: 0.2839\nEpoch 48/100\nTraining Loss: 0.3169\nEpoch 49/100\nTraining Loss: 0.2542\nEpoch 50/100\nTraining Loss: 0.2137\nEpoch 51/100\nTraining Loss: 0.2897\nEpoch 52/100\nTraining Loss: 0.1811\nEpoch 53/100\nTraining Loss: 0.1835\nEpoch 54/100\nTraining Loss: 0.1510\nEpoch 55/100\nTraining Loss: 0.2071\nEpoch 56/100\nTraining Loss: 0.1353\nEpoch 57/100\nTraining Loss: 0.1553\nEpoch 58/100\nTraining Loss: 0.1516\nEpoch 59/100\nTraining Loss: 0.1581\nEpoch 60/100\nTraining Loss: 0.1512\nEpoch 61/100\nTraining Loss: 0.1130\nEpoch 62/100\nTraining Loss: 0.0832\nEpoch 63/100\nTraining Loss: 0.1014\nEpoch 64/100\nTraining Loss: 0.0969\nEpoch 65/100\nTraining Loss: 0.0595\nEpoch 66/100\nTraining Loss: 0.1010\nEpoch 67/100\nTraining Loss: 0.0699\nEpoch 68/100\nTraining Loss: 0.0829\nEpoch 69/100\nTraining Loss: 0.0687\nEpoch 70/100\nTraining Loss: 0.1029\nEpoch 71/100\nTraining Loss: 0.0537\nEpoch 72/100\nTraining Loss: 0.0504\nEpoch 73/100\nTraining Loss: 0.0995\nEpoch 74/100\nTraining Loss: 0.0410\nEpoch 75/100\nTraining Loss: 0.0570\nEpoch 76/100\nTraining Loss: 0.0529\nEpoch 77/100\nTraining Loss: 0.0482\nEpoch 78/100\nTraining Loss: 0.0607\nEpoch 79/100\nTraining Loss: 0.0450\nEpoch 80/100\nTraining Loss: 0.0495\nEpoch 81/100\nTraining Loss: 0.0377\nEpoch 82/100\nTraining Loss: 0.0438\nEpoch 83/100\nTraining Loss: 0.0307\nEpoch 84/100\nTraining Loss: 0.0421\nEpoch 85/100\nTraining Loss: 0.0343\nEpoch 86/100\nTraining Loss: 0.0408\nEpoch 87/100\nTraining Loss: 0.0321\nEpoch 88/100\nTraining Loss: 0.0269\nEpoch 89/100\nTraining Loss: 0.0334\nEpoch 90/100\nTraining Loss: 0.0226\nEpoch 91/100\nTraining Loss: 0.0365\nEpoch 92/100\nTraining Loss: 0.0273\nEpoch 93/100\nTraining Loss: 0.0395\nEpoch 94/100\nTraining Loss: 0.0293\nEpoch 95/100\nTraining Loss: 0.0281\nEpoch 96/100\nTraining Loss: 0.0384\nEpoch 97/100\nTraining Loss: 0.0285\nEpoch 98/100\nTraining Loss: 0.0277\nEpoch 99/100\nTraining Loss: 0.0244\nEpoch 100/100\nTraining Loss: 0.0236\nExecution time: 13.71817398071289\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Run the training process","metadata":{"id":"RASvcPZbau9t"}},{"cell_type":"markdown","source":"Note: Don't run this if you have run using the distributed training","metadata":{"id":"Haly4qb9uuzW"}},{"cell_type":"code","source":"# Define the model\n\n\n\n\n\nmodel = GRU4REC(\n\n    rnn_params=[\n\n        {\"units\": 128},\n\n        {\"units\": 128},\n\n        {\"units\": 64}\n\n    ],\n\n    item_embed_dim=32,\n\n    genre_embed_dim=32,\n\n    ffn1_units=256,\n\n    feature_dense_units=16,\n\n    preprocessed_data=preprocessor\n\n)\n\n","metadata":{"id":"PSkPj14Jau9u","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:08:18.271770Z","iopub.execute_input":"2024-12-11T15:08:18.272453Z","iopub.status.idle":"2024-12-11T15:08:18.298290Z","shell.execute_reply.started":"2024-12-11T15:08:18.272419Z","shell.execute_reply":"2024-12-11T15:08:18.297457Z"}},"outputs":[{"name":"stdout","text":"items size: 10676\ngenres size: 1200\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Compile the model\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_object_ = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n                                                                 reduction='none')\n    loss_ = loss_object_(real, pred)\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)\n    \n# Train the model\n\ntrain_gru4rec(model=model, train_dataset=dataset,optimizer=optimizer, epochs=10, k=8, loss_fn=loss_function)","metadata":{"id":"GlczKLIHau9v","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_recall_at_k(predicted_items, targets, k):\n    \"\"\"\n    Compute the recall@k for the given predictions and targets.\n    \n    Args:\n    - predicted_items: The predicted items (batch_size, seq_length, num_of_unique_items).\n    - targets: The actual next items (batch_size, seq_length).\n    - k: The top-k value for recall calculation.\n    \n    Returns:\n    - recall_at_k: The recall at k metric.\n    \"\"\"\n    # Mask to ignore padding (0 value) in target\n    valid_mask = targets != 0  # Ignoring padding value (0)\n\n    # Create a tensor of top-k predictions for the entire batch\n    top_k_predictions = tf.argsort(predicted_items, axis=-1, direction='DESCENDING')[..., :k]\n\n    # Compute true positives\n    # Reshape targets to match top_k_predictions shape for comparison\n    targets_expanded = tf.expand_dims(targets, axis=-1)\n    \n    # Check if targets are in top-k predictions\n    matches = tf.reduce_any(tf.equal(top_k_predictions, targets_expanded), axis=-1)\n    \n    # Apply the valid mask to focus on non-padding items\n    matches = tf.boolean_mask(matches, valid_mask)\n    \n    # Calculate recall\n    total_true_positives = tf.reduce_sum(tf.cast(matches, tf.float32))\n    total_relevant_items = tf.reduce_sum(tf.cast(valid_mask, tf.float32))\n    \n    # Compute recall\n    recall_at_k = total_true_positives / (total_relevant_items + tf.keras.backend.epsilon())\n    \n    return recall_at_k\n\n# Initialize variables to calculate overall recall\nmean_recall_at_k = 0\n\n# Loop through training dataset and predict the most probable item\nk = 10\nfor step, batch in enumerate(dataset.take(10)):  # Ensure correct syntax for take()\n\n    item_sequences = batch['item']\n    item_genres = batch['genre']\n    item_features = batch['features']\n    targets = batch['next_item']\n\n    # Get the predicted items (predicted items should be a sequence)\n    predicted_items = model((item_sequences, item_features, item_genres), training=False)  # Assuming predict function is implemented\n    # print(\"Predicted Item Shape:\", predicted_items.shape)\n\n    batch_recall_at_k = compute_recall_at_k(predicted_items, targets, k)\n\n    print(f\"Batch {step + 1} Recall at {k}: {batch_recall_at_k:.4f}\")\n    mean_recall_at_k = (mean_recall_at_k*(step) + batch_recall_at_k) / (step+1)\n\nprint(f\"Average Recall@{k} = {mean_recall_at_k}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dmy4kH_bau9v","outputId":"a43ccf20-8f5c-458a-df54-8df1827b206f","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:35:59.975495Z","iopub.execute_input":"2024-12-12T14:35:59.975922Z","iopub.status.idle":"2024-12-12T14:36:01.016468Z","shell.execute_reply.started":"2024-12-12T14:35:59.975880Z","shell.execute_reply":"2024-12-12T14:36:01.015380Z"}},"outputs":[{"name":"stdout","text":"Batch 1 Recall at 10: 1.0000\nBatch 2 Recall at 10: 1.0000\nBatch 3 Recall at 10: 1.0000\nBatch 4 Recall at 10: 0.9612\nBatch 5 Recall at 10: 0.9615\nBatch 6 Recall at 10: 0.9881\nBatch 7 Recall at 10: 1.0000\nBatch 8 Recall at 10: 0.9412\nBatch 9 Recall at 10: 1.0000\nBatch 10 Recall at 10: 1.0000\nAverage Recall@10 = 0.9852050542831421\n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"def preprocess_data_single_session(\n\n    session,\n\n    feature_columns,\n\n    k=1\n\n):\n\n    \"\"\"\n\n    Preprocess a single session into TensorFlow dataset with split genre and features.\n\n\n\n    Args:\n\n    - session (list): A list of dictionaries containing session data.\n\n    - feature_columns (list): List of numerical feature column names.\n\n    - mean_values (dict): Mean values for numerical features for normalization.\n\n    - std_values (dict): Std values for numerical features for normalization.\n\n    - k (int): Minimum length of `next_item_sequences`.\n\n\n\n    Returns:\n\n    - tf.data.Dataset: TensorFlow dataset containing preprocessed data.\n\n    \"\"\"\n\n    item_sequences = []\n\n    next_item_sequences = []\n\n    genre_sequences = []\n\n    feature_sequences = []\n\n\n\n    for i in range(len(session) - 1):\n\n        # Process items\n\n        session_item_encoded = preprocessor.preprocess_song_id(session[i]['SongID'])\n\n        next_session_item_encoded = preprocessor.preprocess_song_id(session[i + 1]['SongID'])\n\n        item_sequences.append(session_item_encoded)\n\n        next_item_sequences.append(next_session_item_encoded)\n\n\n\n        # Process genre\n\n        genre_cleaned = preprocessor.clean_genre(session[i].get('spotify_genre', None))\n\n        genre_sequences.append(genre_cleaned)\n\n\n\n        # Process numerical features\n\n        numeric_features = []\n\n        for col in feature_columns:\n\n            if col != 'spotify_genre':\n\n                mean = preprocessor.mean_values.get(col, None)\n\n                std = preprocessor.std_values.get(col, None)\n\n                cleaned_feature = preprocessor.clean_numeric_feature(session[i].get(col, None), mean=mean, std=std)\n\n                numeric_features.append(cleaned_feature)\n\n\n\n        feature_sequences.append(numeric_features)\n\n\n\n    # Filter session if next_item_sequences length is not greater than k\n\n    if len(next_item_sequences) <= k:\n\n        print(f\"Session skipped because next item sequence length is {len(next_item_sequences)}.\")\n\n        return\n\n\n\n    print(f\"Processed session with {len(item_sequences)} items.\")\n\n\n\n    # Convert to tensors\n\n    item_sequences = tf.stack(item_sequences, axis=0)\n\n    next_item_sequences = tf.stack(next_item_sequences, axis=0)\n\n    genre_sequences_tensor = tf.constant(genre_sequences, dtype=tf.int32)\n\n    feature_sequences_tensor = tf.constant(feature_sequences, dtype=tf.float32)\n\n\n\n    # Create TensorFlow dataset\n\n    dataset = tf.data.Dataset.from_tensor_slices({\n\n        'item': item_sequences,\n\n        'genre': genre_sequences_tensor,\n\n        'features': feature_sequences_tensor,\n\n        'next_item': next_item_sequences\n\n    })\n\n\n\n    return dataset","metadata":{"id":"KyEfocm_yBRR"},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"# Note: Pakai Cara 3 (itu yang bener)","metadata":{"id":"r37Q_7lRu5_O"}},{"cell_type":"markdown","source":"## Cara 1","metadata":{"id":"vzF4yZg47oey"}},{"cell_type":"code","source":"def predict_next(model, item_sequences, item_features, item_genres):\n\n    \"\"\"\n\n    Predict the next item for a given input sequence.\n\n\n\n    Args:\n\n    - model: The trained model.\n\n    - item_sequences: Input item sequences (batch_size, seq_length).\n\n    - item_features: Input item features (batch_size, feature_length).\n\n    - item_genres: Input item genres (batch_size, genre_length).\n\n\n\n    Returns:\n\n    - predicted_items: Predicted next item (batch_size,).\n\n    \"\"\"\n\n    # Run inference\n\n    _, logits = model((item_sequences, item_features, item_genres), training=False)\n\n    # print(\"Logits:\", logits)\n\n\n\n    # Apply softmax to logits to get probabilities\n\n    probabilities = tf.nn.softmax(logits, axis=-1)\n\n\n\n    # Select the item with the highest probability\n\n    predicted_items = tf.argmax(probabilities, axis=-1, output_type=tf.int32)\n\n\n\n    return predicted_items.numpy()\n\n\n\n\n\ndef compute_recall_at_k(predicted_sequence, target_sequence, k):\n\n    \"\"\"\n\n    Compute Recall@k for a given session.\n\n\n\n    Args:\n\n    - predicted_sequence: The predicted sequence of items.\n\n    - target_sequence: The actual target sequence of items.\n\n    - k: The number of items in the predicted sequence.\n\n\n\n    Returns:\n\n    - recall_at_k: Recall@k value.\n\n    \"\"\"\n\n    # Count how many of the target items appear in the predicted sequence\n\n    predicted_ids = [item['SongID'] if isinstance(item, dict) else item for item in predicted_sequence]\n\n    target_ids = [item['SongID'] if isinstance(item, dict) else item for item in target_sequence]\n\n\n\n    # Count how many of the target items appear in the predicted sequence\n\n    hits = len(set(predicted_ids[:k]) & set(target_ids[:k]))\n\n    return hits / len(target_ids[:k]) if target_ids[:k] else 0.0\n\n    return hits / len(target_sequence[:k])\n\n\n\n\n\n# Initialize overall metrics\n\ntotal_recall = 0\n\nsession_count = 0\n\nk = 10  # Set the value of k\n\nprint(\"Creating session dataset\")\n\nsessions_data = preprocessor.create_session_dataset(preprocessor.train_df)  # Use train data for training\n\nprint(\"Creating tensor dataset\")\n\n# Process each session in the dataset\n\nfor session in sessions_data[:100]:  # Assume train_sessions is your preprocessed session data\n\n    if len(session) <= k:\n\n      continue\n\n    # print(session)\n\n    context_length = len(session) - k\n\n    context = session[:context_length]\n\n    target = session[context_length:]\n\n    dataset = preprocess_data_single_session(session, feature_columns, k=k)\n\n    if dataset is None:\n\n        continue\n\n    dataset = dataset.batch(1)\n\n    predicted_sequence = []\n\n    current_sequence = context\n\n\n\n    # Generate k predictions iteratively\n\n    for batch in dataset:\n\n        # Prepare input features for the current sequence\n\n        item_sequences = batch['item']  # Batch of size 1\n\n        item_features = batch['features']  # Extract corresponding features\n\n        item_genres = batch['genre']  # Extract corresponding genres\n\n\n\n        # Predict the next item\n\n        predicted_item = predict_next(model, item_sequences, item_features, item_genres)\n\n        predicted_sequence.append(predicted_item[0])  # Append the prediction\n\n\n\n        # Update the current sequence\n\n        current_sequence = current_sequence[1:] + [predicted_item[0]]\n\n\n\n        if len(predicted_sequence) >= k:\n\n            break\n\n    ori_pred_seq = preprocessor.song_id_encoder.inverse_transform(predicted_sequence)\n\n    print(f\"Predicted Sequence: {ori_pred_seq}\")\n\n    # target_ids = preprocessor.song_id_encoder.transform([item['SongID'] if isinstance(item, dict) else item for item in target])\n\n    print(f\"True Sequence: {[item['SongID'] for item in target]}\")\n\n\n\n    # check genre\n\n    original_item_genres = preprocessor.train_df.loc[preprocessor.train_df['SongID'].isin([item['SongID'] if isinstance(item, dict) else item for item in target]), 'spotify_genre'].values\n\n    # print(f\"Original Item Genres: {original_item_genres}\")\n\n    predicted_item_genres = preprocessor.train_df.loc[preprocessor.train_df['SongID'].isin([item['SongID'] if isinstance(item, dict) else item for item in ori_pred_seq]), 'spotify_genre'].values\n\n    # print(f\"Predicted Item Genres: {predicted_item_genres}\")\n\n    # Calculate Recall@k for the current session\n\n    session_recall = compute_recall_at_k(predicted_sequence, target, k)\n\n    total_recall += session_recall\n\n    session_count += 1\n\n\n\n    print(f\"Session recall: {session_recall:.4f}\")\n\n\n\n# Calculate overall Recall@k\n\noverall_recall_at_k = total_recall / session_count if session_count > 0 else 0\n\nprint(f\"Overall Recall@{k}: {overall_recall_at_k:.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZAs7Kq0au9w","outputId":"d2c3c328-2726-4dde-ee9b-933c4fb89af7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cara 2","metadata":{"id":"tbOSEngl7lMn"}},{"cell_type":"code","source":"import tensorflow as tf\n\n\n\ndef predict_next(model, item_sequences, item_features, item_genres, k=5):\n\n    \"\"\"\n\n    Predict the next item for a given input sequence.\n\n\n\n    Args:\n\n    - model: The trained model.\n\n    - item_sequences: Input item sequences (batch_size, seq_length).\n\n    - item_features: Input item features (batch_size, feature_length).\n\n    - item_genres: Input item genres (batch_size, genre_length).\n\n    - k: Number of top predictions to consider.\n\n\n\n    Returns:\n\n    - predicted_items: Top k predicted next items (batch_size, k).\n\n    \"\"\"\n\n    # Run inference\n\n    _, logits = model((item_sequences, item_features, item_genres), training=False)\n\n\n\n    # Apply softmax to logits to get probabilities\n\n    probabilities = tf.nn.softmax(logits, axis=-1)\n\n\n\n    # Get the top k predictions\n\n    top_k_values, top_k_indices = tf.nn.top_k(probabilities, k=k, sorted=True)\n\n\n\n    return top_k_indices.numpy()  # Return top k item indices\n\n\n\ndef compute_recall_at_k(predicted_sequence, target_sequence, k):\n\n    \"\"\"\n\n    Compute Recall@k for a given session.\n\n\n\n    Args:\n\n    - predicted_sequence: The predicted sequence of items.\n\n    - target_sequence: The actual target sequence of items.\n\n    - k: The number of top predictions to consider.\n\n\n\n    Returns:\n\n    - recall_at_k: Recall@k value.\n\n    \"\"\"\n\n    # Extract 'SongID' from dictionaries if needed\n\n    predicted_ids = [item['SongID'] if isinstance(item, dict) else item for item in predicted_sequence]\n\n    target_ids = [item['SongID'] if isinstance(item, dict) else item for item in target_sequence]\n\n\n\n    # Select the top k items from predicted sequence\n\n    top_k_predicted = predicted_ids[:k]\n\n\n\n    # Count how many of the target items appear in the top k predictions\n\n    hits = len(set(top_k_predicted) & set(target_ids[:k]))\n\n    return hits / len(target_ids[:k]) if target_ids[:k] else 0.0\n\n\n\n\n\n# Initialize overall metrics\n\ntotal_recall = 0\n\nsession_count = 0\n\nk = 5  # Set the value of k\n\n\n\nprint(\"Creating session dataset\")\n\nsessions_data = preprocessor.create_session_dataset(preprocessor.train_df)  # Use train data for training\n\nprint(\"Creating tensor dataset\")\n\n\n\n# Process each session in the dataset\n\nfor session in sessions_data:  # Assume sessions_data is your preprocessed session data\n\n    if len(session) <= k:\n\n        continue\n\n    print(session)\n\n    context_length = len(session) - k\n\n    context = session[:context_length]\n\n    target = session[context_length:]\n\n    dataset = preprocess_data_single_session(session, feature_columns, k=k)\n\n    if dataset is None:\n\n        continue\n\n    dataset = dataset.batch(1)\n\n    predicted_sequence = []\n\n    current_sequence = context\n\n\n\n    # Generate k predictions iteratively\n\n    for batch in dataset:\n\n        # Prepare input features for the current sequence\n\n        item_sequences = batch['item']  # Batch of size 1\n\n        item_features = batch['features']  # Extract corresponding features\n\n        item_genres = batch['genre']  # Extract corresponding genres\n\n\n\n        # Predict the top k items\n\n        top_k_predictions = predict_next(model, item_sequences, item_features, item_genres, k=k)\n\n\n\n        # Append the top k predictions to the sequence (only append first item from the top k)\n\n        predicted_sequence.extend(top_k_predictions[0])  # Assuming batch size is 1\n\n\n\n        # Update the current sequence\n\n        current_sequence = current_sequence[1:] + [top_k_predictions[0][0]]  # Only use first predicted item for the next context\n\n\n\n        if len(predicted_sequence) >= k:\n\n            break\n\n\n\n    # Calculate Recall@k for the current session\n\n    session_recall = compute_recall_at_k(predicted_sequence, target, k)\n\n    total_recall += session_recall\n\n    session_count += 1\n\n\n\n    print(f\"Session recall: {session_recall:.4f}\")\n\n\n\n# Calculate overall Recall@k\n\noverall_recall_at_k = total_recall / session_count if session_count > 0 else 0\n\nprint(f\"Overall Recall@{k}: {overall_recall_at_k:.4f}\")\n","metadata":{"id":"KRbYXzqWwHJa"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cara 3","metadata":{"id":"MVjdRzAd7th2"}},{"cell_type":"code","source":"import tensorflow as tf\n\n\n\ndef predict_next(model, item_sequences, item_features, item_genres, k=5):\n\n    \"\"\"\n\n    Predict the next item for a given input sequence.\n\n\n\n    Args:\n\n    - model: The trained model.\n\n    - item_sequences: Input item sequences (batch_size, seq_length).\n\n    - item_features: Input item features (batch_size, feature_length).\n\n    - item_genres: Input item genres (batch_size, genre_length).\n\n    - k: The number of top predictions to return.\n\n\n\n    Returns:\n\n    - predicted_items: Top-k predicted items (batch_size, k).\n\n    \"\"\"\n\n    # Run inference\n\n    pred_sequence = model((item_sequences, item_features, item_genres), training=False)\n\n    \n\n    # Apply softmax to logits to get probabilities\n\n    probabilities = tf.nn.softmax(logits, axis=-1)\n\n\n\n    # Get the top-k predicted item indices based on probabilities\n\n    top_k_indices = tf.argsort(probabilities, axis=-1, direction='DESCENDING')[:, :k]\n\n\n\n    return top_k_indices.numpy()\n\n\n\n\n\n# Initialize overall metrics\n\ntotal_recall = 0\n\nsession_count = 0\n\nk = 10 # Set the value of k\n\nprint(\"Creating session dataset\")\n\nsessions_data = preprocessor.create_session_dataset(preprocessor.train_df)  # Use train data for training\n\nprint(\"Creating tensor dataset\")\n\n\n\n# Process each session in the dataset\n\nfor session in sessions_data:  # Assume train_sessions is your preprocessed session data\n\n    if len(session) <= k:\n\n        continue\n\n\n\n    context_length = len(session) - k\n\n    context = session[:context_length]\n\n    target = session[context_length:]\n\n    dataset_for_prediction = preprocess_data_single_session(session, feature_columns, k=k)\n\n    if dataset_for_prediction is None:\n\n        continue\n\n    dataset_for_prediction = dataset_for_prediction.batch(1)\n\n    predicted_sequence = []\n\n\n\n    # Generate k predictions iteratively\n\n    for batch in dataset_for_prediction:\n\n        # Prepare input features for the current sequence\n\n        item_sequences = batch['item']  # Batch of size 1\n\n        item_features = batch['features']  # Extract corresponding features\n\n        item_genres = batch['genre']  # Extract corresponding genres\n\n\n\n        # Predict the top k items\n\n        top_k_predictions = predict_next(model, item_sequences, item_features, item_genres, k)\n\n\n\n        # Add the top-k predictions to the predicted sequence\n\n        predicted_sequence.extend(top_k_predictions[0])  # Extend by top-k predicted items\n\n\n\n        if len(predicted_sequence) >= k:\n\n            break\n\n\n\n    ori_pred_seq = preprocessor.song_id_encoder.inverse_transform(predicted_sequence)\n\n    print(ori_pred_seq)\n\n    predicted_song_genre = [\n\n      {'SongID': item, 'Genre': preprocessor.train_df.loc[preprocessor.train_df['SongID'] == item, 'spotify_genre'].values[0]}\n\n      for item in ori_pred_seq\n\n    ]\n\n\n\n    # Extract SongID and genre for the true sequence\n\n    true_song_genre = [\n\n        {'SongID': item['SongID'], 'Genre': preprocessor.train_df.loc[preprocessor.train_df['SongID'] == item['SongID'], 'spotify_genre'].values[0]}\n\n        for item in target\n\n    ]\n\n\n\n    for true, predicted in zip(true_song_genre, predicted_song_genre):\n\n        print(f\"Predicted SongID: {predicted['SongID']}; True SongID: {true['SongID']}\")\n\n        print(f\"Predicted Genre: {predicted['Genre']}; True Genre: {true['Genre']}\")\n\n        print('=====================================================================')\n\n\n\n    # Print the predicted and true sequences with SongID and Genre\n\n    print(f\"Predicted Sequence: {predicted_song_genre}\")\n\n    print(f\"True Sequence: {true_song_genre}\")\n\n    # Calculate Recall@k for the current session\n\n    session_recall = compute_recall_at_k(predicted_sequence, target, k)\n\n    total_recall += session_recall\n\n    session_count += 1\n\n\n\n    print(f\"Session recall: {session_recall:.4f}\")\n\n\n\n# Calculate overall Recall@k\n\noverall_recall_at_k = total_recall / session_count if session_count > 0 else 0\n\nprint(f\"Overall Recall@{k}: {overall_recall_at_k:.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mdr6XBLu6sCq","outputId":"1863021a-582d-4fc7-8581-427a2026707d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## display training history","metadata":{"id":"zDXnvTfLpp-c"}},{"cell_type":"code","source":"def plot_training_history(loss_history, metric_name=\"Metric\", metric_history=None):\n\n    \"\"\"Plot the training loss and specified metric.\"\"\"\n\n    epochs = range(1, len(loss_history) + 1)\n\n\n\n    # Create subplots\n\n    if metric_history is not None:\n\n        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n\n    else:\n\n        fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n\n\n\n    # Plot the training loss\n\n    ax1.plot(epochs, loss_history, label='Loss', color='blue', linestyle='-', marker='o')\n\n    ax1.set_title('Training Loss')\n\n    ax1.set_xlabel('Epochs')\n\n    ax1.set_ylabel('Loss')\n\n    ax1.legend()\n\n    ax1.grid(True)\n\n\n\n    # Plot the specified metric if provided\n\n    if metric_history is not None:\n\n        ax2.plot(epochs, metric_history, label=metric_name, color='green', linestyle='-', marker='o')\n\n        ax2.set_title(f'Training {metric_name}')\n\n        ax2.set_xlabel('Epochs')\n\n        ax2.set_ylabel(metric_name)\n\n        ax2.legend()\n\n        ax2.grid(True)\n\n\n\n    plt.tight_layout()\n\n    plt.show()","metadata":{"id":"d5VUMhUapxyL","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:49:40.412009Z","iopub.execute_input":"2024-12-12T15:49:40.412353Z","iopub.status.idle":"2024-12-12T15:49:40.419154Z","shell.execute_reply.started":"2024-12-12T15:49:40.412324Z","shell.execute_reply":"2024-12-12T15:49:40.418236Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"plot_training_history(history['loss_history'])","metadata":{"id":"DEDRp9VQ676h","colab":{"base_uri":"https://localhost:8080/","height":607},"outputId":"5bdbc2e5-54bb-4702-f00a-7b0ef7f4ef37","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:49:42.005007Z","iopub.execute_input":"2024-12-12T15:49:42.005362Z","iopub.status.idle":"2024-12-12T15:49:42.355486Z","shell.execute_reply.started":"2024-12-12T15:49:42.005331Z","shell.execute_reply":"2024-12-12T15:49:42.354700Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"# Save model","metadata":{"id":"Ye4bsSrJrlW_"}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import joblib\n\ntry:\n    print(\"Inverse Transformed Labels:\")\n    for idx in range(len(preprocessor.song_id_encoder.classes_)):\n        print(f\"Index {idx+1}: {preprocessor.song_id_encoder.inverse_transform([idx])[0]}\")\n    print(\"\\n===============================\\n\")\n    for idx in range(len(preprocessor.genre_encoder.classes_)):\n        print(f\"Index {idx+1}: {preprocessor.genre_encoder.inverse_transform([idx])[0]}\")\n    joblib.dump(preprocessor.song_id_encoder, \"song_encoder.pkl\")\n    joblib.dump(preprocessor.genre_encoder, \"genre_encoder.pkl\")\n    print(\"All the encoder are successfully saved\")\nexcept Exception as e:\n    print(str(e))    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:51:35.710929Z","iopub.execute_input":"2024-12-12T15:51:35.711690Z","iopub.status.idle":"2024-12-12T15:51:35.732969Z","shell.execute_reply.started":"2024-12-12T15:51:35.711651Z","shell.execute_reply":"2024-12-12T15:51:35.732134Z"}},"outputs":[{"name":"stdout","text":"Inverse Transformed Labels:\nIndex 1: Come Sail AwayStyx\nIndex 2: Devil's EyesGreyhounds\nIndex 3: Don't Stop Believin'Journey\nIndex 4: Down UnderMen at Work\nIndex 5: EclipsePink Floyd\nIndex 6: Feeling GoodMuse\nIndex 7: Johnny B. GoodeChuck Berry\nIndex 8: Just a Job to Do - 2007 RemasterGenesis\nIndex 9: Knights of CydoniaMuse\nIndex 10: LydiaHighly Suspect\nIndex 11: Make Peace and be FreePerfect Confusion\nIndex 12: Our Special PlaceThe Heavy\nIndex 13: Owner of a Lonely HeartYes\nIndex 14: ParalyzerFinger Eleven\nIndex 15: Pussy and PizzaMurs\nIndex 16: Put It In The BoogieZach Deputy\nIndex 17: Salute Your SolutionThe Raconteurs\nIndex 18: Saving GraceTom Petty\nIndex 19: Since I Lost YouGenesis\nIndex 20: StopPink Floyd\nIndex 21: StrangleholdTed Nugent\nIndex 22: Take a BowMuse\nIndex 23: The Chain - 2004 RemasterFleetwood Mac\nIndex 24: The Moon Is DisgustingThat 1 Guy\nIndex 25: Twenty Five MilesEdwin Starr\n\n===============================\n\nIndex 1: album rock\nIndex 2: alternative metal\nIndex 3: alternative rock\nIndex 4: art rock\nIndex 5: australian rock\nIndex 6: bath indie\nIndex 7: blues rock\nIndex 8: canadian rock\nIndex 9: classic rock\nIndex 10: classic soul\nIndex 11: dance pop\nIndex 12: dance rock\nIndex 13: deep new americana\nIndex 14: europop\nIndex 15: folk rock\nIndex 16: funk\nIndex 17: funk metal\nIndex 18: garage rock\nIndex 19: glam metal\nIndex 20: hard rock\nIndex 21: heartland rock\nIndex 22: indie rock\nIndex 23: jam band\nIndex 24: jazz fusion\nIndex 25: mellow gold\nIndex 26: metal\nIndex 27: modern blues rock\nIndex 28: modern rock\nIndex 29: motown\nIndex 30: neo mellow\nIndex 31: new romantic\nIndex 32: new wave\nIndex 33: new wave pop\nIndex 34: northern soul\nIndex 35: nu metal\nIndex 36: one-person band\nIndex 37: permanent wave\nIndex 38: piano rock\nIndex 39: pop\nIndex 40: pop rap\nIndex 41: pop rock\nIndex 42: post-grunge\nIndex 43: post-teen pop\nIndex 44: progressive rock\nIndex 45: psychedelic rock\nIndex 46: quiet storm\nIndex 47: rap rock\nIndex 48: rock\nIndex 49: rock-and-roll\nIndex 50: rockabilly\nIndex 51: roots rock\nIndex 52: singer-songwriter\nIndex 53: soft rock\nIndex 54: soul\nIndex 55: southern rock\nIndex 56: southern soul\nIndex 57: symphonic rock\nIndex 58: talent show\nIndex 59: uk pop\nIndex 60: wrestling\nIndex 61: yacht rock\nAll the encoder are successfully saved\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Save the trained model to an H5 file\n\n# mirrored_model.save(\"gru4rec_model.keras\")\ntry:\n    model.save(\"gru4rec_model.keras\")\n    print(\"Model successfully saved\")\nexcept Exception as e:\n    print(str(e))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soidj3f9qNgh","outputId":"4becb233-e371-4115-bb5f-7b9a5ceb2a1d","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:55:26.834638Z","iopub.execute_input":"2024-12-12T15:55:26.835520Z","iopub.status.idle":"2024-12-12T15:55:26.874223Z","shell.execute_reply.started":"2024-12-12T15:55:26.835481Z","shell.execute_reply":"2024-12-12T15:55:26.873384Z"}},"outputs":[{"name":"stdout","text":"Model successfully saved\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# Test Load model","metadata":{"id":"WSiZRK4I3nGG"}},{"cell_type":"code","source":"loaded_encoder = joblib.load('song_encoder.pkl')\nprint(df['SongID'][1])\n\nids = [df['SongID'][1]]\n\ntransformed_ids = loaded_encoder.transform(ids)\nprint(transformed_ids)\ntransformed_ids = loaded_encoder.inverse_transform(transformed_ids)\nprint(transformed_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:00:56.553223Z","iopub.execute_input":"2024-12-12T15:00:56.554241Z","iopub.status.idle":"2024-12-12T15:00:56.577801Z","shell.execute_reply.started":"2024-12-12T15:00:56.554187Z","shell.execute_reply":"2024-12-12T15:00:56.576857Z"}},"outputs":[{"name":"stdout","text":"Devil's EyesGreyhounds\n[2080]\n[\"Devil's EyesGreyhounds\"]\n","output_type":"stream"}],"execution_count":144},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nloaded_model = load_model(\n\n    \"gru4rec_model.keras\",\n    safe_mode=False,\n    custom_objects = {\n        'GRU4REC': GRU4REC\n    }\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"0WgtMdwfrnDW","outputId":"ddcf75fd-cefe-41d0-ba43-7c3ac2cf3f5e","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:55:42.800978Z","iopub.execute_input":"2024-12-12T15:55:42.801372Z","iopub.status.idle":"2024-12-12T15:55:43.103012Z","shell.execute_reply.started":"2024-12-12T15:55:42.801340Z","shell.execute_reply":"2024-12-12T15:55:43.102360Z"}},"outputs":[{"name":"stdout","text":"items size: 25\ngenres size: 61\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"weights = loaded_model.get_weights()\n\n# Check if weights are non-zero\nis_trained = any(np.any(w != 0) for w in weights)\n\nif is_trained:\n    print(\"The model appears to be trained (non-zero weights).\")\nelse:\n    print(\"The model is not trained (weights are all zero or uninitialized).\")","metadata":{"id":"8hZiuO9Lrvrn","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:55:44.556580Z","iopub.execute_input":"2024-12-12T15:55:44.556920Z","iopub.status.idle":"2024-12-12T15:55:44.568282Z","shell.execute_reply.started":"2024-12-12T15:55:44.556889Z","shell.execute_reply":"2024-12-12T15:55:44.567288Z"}},"outputs":[{"name":"stdout","text":"The model appears to be trained (non-zero weights).\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# sequence_length = loaded_model.layers[0].input_shape[1]  # Assuming the input shape is (batch_size, sequence_length, features)\n# print(f\"Model expects input sequences of length: {sequence_length}\")\n\n# input_shape = loaded_model.input\n# print(f\"Model expects input shape: {input_shape}\")\n\nfor i, layer in enumerate(loaded_model.layers):\n    print(f\"Layer {i}: {layer.name}\")\n    print(f\"Type: {type(layer)}\")\n    print(f\"Config: {layer.get_config()}\")\n    print(\"---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:55:51.416663Z","iopub.execute_input":"2024-12-12T15:55:51.416995Z","iopub.status.idle":"2024-12-12T15:55:51.425420Z","shell.execute_reply.started":"2024-12-12T15:55:51.416965Z","shell.execute_reply":"2024-12-12T15:55:51.424455Z"}},"outputs":[{"name":"stdout","text":"Layer 0: embedding_4\nType: <class 'keras.src.layers.core.embedding.Embedding'>\nConfig: {'name': 'embedding_4', 'trainable': True, 'dtype': 'float32', 'input_dim': 25, 'output_dim': 32, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': True}\n---\nLayer 1: genre_embedding\nType: <class 'keras.src.layers.core.embedding.Embedding'>\nConfig: {'name': 'genre_embedding', 'trainable': True, 'dtype': 'float32', 'input_dim': 61, 'output_dim': 32, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': True}\n---\nLayer 2: gru_12\nType: <class 'keras.src.layers.rnn.gru.GRU'>\nConfig: {'name': 'gru_12', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}\n---\nLayer 3: gru_13\nType: <class 'keras.src.layers.rnn.gru.GRU'>\nConfig: {'name': 'gru_13', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}\n---\nLayer 4: gru_14\nType: <class 'keras.src.layers.rnn.gru.GRU'>\nConfig: {'name': 'gru_14', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}\n---\nLayer 5: concat_1\nType: <class 'keras.src.layers.merging.concatenate.Concatenate'>\nConfig: {'name': 'concat_1', 'trainable': True, 'dtype': 'float32', 'axis': -1}\n---\nLayer 6: batchnorm\nType: <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>\nConfig: {'name': 'batchnorm', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}\n---\nLayer 7: dropout\nType: <class 'keras.src.layers.regularization.dropout.Dropout'>\nConfig: {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'seed': None, 'noise_shape': None}\n---\nLayer 8: feature_dense\nType: <class 'keras.src.layers.core.dense.Dense'>\nConfig: {'name': 'feature_dense', 'trainable': True, 'dtype': 'float32', 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n---\nLayer 9: ffn_1\nType: <class 'keras.src.layers.core.dense.Dense'>\nConfig: {'name': 'ffn_1', 'trainable': True, 'dtype': 'float32', 'units': 256, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n---\nLayer 10: freaky_relu\nType: <class 'keras.src.layers.activations.leaky_relu.LeakyReLU'>\nConfig: {'name': 'freaky_relu', 'trainable': True, 'dtype': 'float32', 'negative_slope': 0.2}\n---\nLayer 11: item_output\nType: <class 'keras.src.layers.core.dense.Dense'>\nConfig: {'name': 'item_output', 'trainable': True, 'dtype': 'float32', 'units': 25, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n---\nLayer 12: attention\nType: <class 'keras.src.layers.attention.attention.Attention'>\nConfig: {'name': 'attention', 'trainable': True, 'dtype': 'float32', 'use_scale': False, 'score_mode': 'dot', 'dropout': 0.2}\n---\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import numpy as np\n\n# Input data\nitems_sequence = np.array([0, 0, 0, 0, 5, 21, 4, 3, 16, 10])\ngenres_sequence = np.array([\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],\n    [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],\n    [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],\n    [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],\n    [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],\n    [1, 2, 3, 4, 5, 0, 0, 0, 0, 0],\n])\n\n# Loaded model target sequence length\ntarget_sequence_length = 20\nextra_dimension = 5\n\n# Step 1: Pad items_sequence to target length\npadded_items_sequence = np.pad(\n    items_sequence, \n    (target_sequence_length - len(items_sequence), 0), \n    mode='constant', \n    constant_values=0\n)\n\n# Step 2: Process genres_sequence\n# Initialize an array of zeros with the new shape\npadded_genres_sequence = np.zeros((target_sequence_length, genres_sequence.shape[1] + extra_dimension))\n\nfor i in range(target_sequence_length):\n    if i < len(items_sequence):\n        padded_row = np.pad(genres_sequence[i], (0, extra_dimension), mode='constant', constant_values=0)\n    else:\n        # Padding beyond original sequence length, keep zeros\n        padded_row = np.pad(np.zeros(genres_sequence.shape[1]), (0, extra_dimension), mode='constant', constant_values=0)\n    padded_genres_sequence[i-len(items_sequence)] = padded_row\n\n# Step 3: Add batch dimension for both sequences\npadded_items_sequence = np.expand_dims(padded_items_sequence, axis=0)  # Shape: (1, sequence_length)\npadded_genres_sequence = np.expand_dims(padded_genres_sequence, axis=0)  # Shape: (1, sequence_length, num_features)\n\n# Step 4: Handle features_sequence (if any)\nfeatures_sequence = np.array([])  # Placeholder\nfeatures_sequence = np.expand_dims(features_sequence, axis=0) if features_sequence.size > 0 else np.empty((1, 0))\n\n# Output results\nprint(\"Padded Items Sequence:\")\nprint(padded_items_sequence)\nprint(\"\\nPadded Genres Sequence:\")\nprint(padded_genres_sequence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:56:10.127442Z","iopub.execute_input":"2024-12-12T15:56:10.127798Z","iopub.status.idle":"2024-12-12T15:56:10.141912Z","shell.execute_reply.started":"2024-12-12T15:56:10.127760Z","shell.execute_reply":"2024-12-12T15:56:10.140939Z"}},"outputs":[{"name":"stdout","text":"Padded Items Sequence:\n[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  5 21  4  3 16 10]]\n\nPadded Genres Sequence:\n[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [1. 2. 3. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [1. 2. 3. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [1. 2. 3. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [1. 2. 3. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [1. 2. 3. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n  [1. 2. 3. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"\n\n# Now the input is ready to be passed to the model\npredicted_sequence = loaded_model(\n    (padded_items_sequence, features_sequence, padded_genres_sequence), \n    training=False\n)\n\ndef remove_duplicates_with_logit_check(logits, sequence_length):\n    # Initialize an empty list for the final sequence\n    predicted_sequence = []\n    print(logits.shape)\n    if (sequence_length > logits.shape[1]):\n        sequence_length = logits.shape[1]\n    # Iterate through the logits (probabilities for each token)\n    for step in range(sequence_length):\n        # Get the current logits and their indices (i.e., token indices)\n        current_logits = logits[0][step]\n        \n        # Sort the logits in descending order to find the highest probability\n        top_indices = tf.argsort(current_logits, direction='DESCENDING')  # Sort logits\n        \n        # Find the next highest logit that is not a duplicate\n        for idx in top_indices:\n            if idx.numpy() not in predicted_sequence:  # Check if the token is already in the sequence\n                predicted_sequence.append(idx.numpy())  # Add the token to the sequence\n                break  # Stop once a unique token is found\n    \n    return predicted_sequence\n\n\n\n# Output prediction\nprint(predicted_sequence)\n\nargmax_indices = tf.argmax(predicted_sequence, axis=2)\n\n# Print the resulting indices\nprint(\"Argmax Indices (Recommendations per Time Step):\")\nprint(argmax_indices.numpy())\n\npredicted_sequence = remove_duplicates_with_logit_check(predicted_sequence, 10)\nprint(predicted_sequence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T16:08:20.848770Z","iopub.execute_input":"2024-12-12T16:08:20.849590Z","iopub.status.idle":"2024-12-12T16:08:20.920341Z","shell.execute_reply.started":"2024-12-12T16:08:20.849548Z","shell.execute_reply":"2024-12-12T16:08:20.919372Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[[-2.64350235e-01 -1.82458699e-01 -5.10224737e-02 -1.32594287e-01\n    4.24034059e-01 -2.22646996e-01 -7.26286620e-02  3.68969142e-03\n    2.07034200e-01  5.34935743e-02 -2.87242502e-01 -3.10737133e-01\n   -3.33111823e-01 -3.50116342e-01 -2.27463081e-01 -2.08265170e-01\n   -1.63888767e-01  3.44475120e-01 -1.33469343e-01  5.97253591e-02\n   -3.27571183e-01 -3.00177217e-01  8.74879509e-02  1.38751622e-02\n   -2.01565638e-01]\n  [-3.60279649e-01 -2.05608845e-01 -2.05883458e-01 -2.83800602e-01\n    9.78247941e-01 -4.12475586e-01 -1.28161088e-01 -1.03829481e-01\n    1.78829044e-01  2.40435004e-01 -3.83056462e-01 -4.17622864e-01\n   -6.09591842e-01 -7.31744587e-01 -2.61064321e-01 -2.37075269e-01\n   -4.70254362e-01  3.87552619e-01 -2.63232827e-01  1.94167159e-02\n   -4.25028652e-01 -4.10641670e-01  3.98418695e-01 -6.71346784e-02\n   -2.31582388e-01]\n  [-4.85054344e-01 -2.59512275e-01 -4.53380704e-01 -4.76277053e-01\n    1.59233689e+00 -6.06990814e-01 -1.36209160e-01 -2.96584874e-01\n    6.31976575e-02  5.00287771e-01 -5.41103303e-01 -5.49925148e-01\n   -8.93648267e-01 -1.12248206e+00 -3.29163313e-01 -3.09796602e-01\n   -8.20115447e-01  3.77977699e-01 -4.34497237e-01  6.26664609e-04\n   -5.61815441e-01 -5.61147630e-01  8.09970140e-01 -2.21074715e-01\n   -2.76011705e-01]\n  [-6.24453604e-01 -3.40224206e-01 -7.70033538e-01 -6.87779248e-01\n    2.20289207e+00 -8.06360364e-01 -1.00522906e-01 -5.63335538e-01\n   -1.30101010e-01  8.25396061e-01 -7.27160811e-01 -7.05093384e-01\n   -1.16397929e+00 -1.48720658e+00 -4.18385178e-01 -3.94556761e-01\n   -1.16979492e+00  3.41272622e-01 -6.50675356e-01  2.60454230e-02\n   -7.29408622e-01 -7.30107844e-01  1.28172123e+00 -4.33712989e-01\n   -3.27288270e-01]\n  [-7.75087953e-01 -4.31951463e-01 -1.11105680e+00 -8.94902110e-01\n    2.75138450e+00 -1.01732016e+00 -4.13388498e-02 -8.71459246e-01\n   -3.81802320e-01  1.18649733e+00 -9.21993971e-01 -8.76747429e-01\n   -1.39881563e+00 -1.80554485e+00 -5.14179349e-01 -4.90030587e-01\n   -1.47623086e+00  3.08392465e-01 -9.04031098e-01  1.06829673e-01\n   -9.17087972e-01 -9.09769833e-01  1.77351153e+00 -6.73055530e-01\n   -3.94599766e-01]\n  [-9.22229409e-01 -5.22817552e-01 -1.43963861e+00 -1.08652246e+00\n    3.21151662e+00 -1.22612643e+00  1.36145353e-02 -1.17276061e+00\n   -6.57195807e-01  1.55792427e+00 -1.11171460e+00 -1.05060899e+00\n   -1.59363353e+00 -2.05869627e+00 -6.15250587e-01 -5.87057769e-01\n   -1.73440182e+00  2.93089360e-01 -1.15963864e+00  2.20138431e-01\n   -1.10094643e+00 -1.08826983e+00  2.24081278e+00 -9.10845578e-01\n   -4.75944757e-01]\n  [-1.07532310e+00 -6.18469954e-01 -1.73926020e+00 -1.25584924e+00\n    3.57513070e+00 -1.42755389e+00  6.07830845e-02 -1.45201147e+00\n   -9.33752656e-01  1.91684425e+00 -1.28891575e+00 -1.22176003e+00\n   -1.75060642e+00 -2.24526668e+00 -7.16274619e-01 -6.84990644e-01\n   -1.94671488e+00  2.97722071e-01 -1.40190923e+00  3.56752962e-01\n   -1.26903749e+00 -1.26100433e+00  2.65490746e+00 -1.13511312e+00\n   -5.60502529e-01]\n  [-1.21993721e+00 -7.05965638e-01 -1.99999046e+00 -1.40014398e+00\n    3.84271502e+00 -1.61254120e+00  9.80709791e-02 -1.70405090e+00\n   -1.19643116e+00  2.24480867e+00 -1.44078040e+00 -1.37787056e+00\n   -1.87204933e+00 -2.37344956e+00 -8.16523433e-01 -7.79326141e-01\n   -2.11453867e+00  3.22173268e-01 -1.62172747e+00  5.02297878e-01\n   -1.42151225e+00 -1.41485584e+00  3.00541091e+00 -1.33379984e+00\n   -6.42940581e-01]\n  [-1.35236382e+00 -7.83880711e-01 -2.21900463e+00 -1.51788974e+00\n    4.03338242e+00 -1.77538037e+00  1.19267821e-01 -1.91565597e+00\n   -1.42595196e+00  2.52634287e+00 -1.56572902e+00 -1.51702499e+00\n   -1.97145522e+00 -2.45799494e+00 -9.12509203e-01 -8.63513649e-01\n   -2.24503660e+00  3.58367354e-01 -1.81192672e+00  6.45560801e-01\n   -1.55723643e+00 -1.55189645e+00  3.28164053e+00 -1.50058055e+00\n   -7.19708383e-01]\n  [-1.46954679e+00 -8.51853013e-01 -2.40431356e+00 -1.60862041e+00\n    4.16156101e+00 -1.91553199e+00  1.27253518e-01 -2.08995032e+00\n   -1.62804890e+00  2.76892376e+00 -1.67019165e+00 -1.63459826e+00\n   -2.04605556e+00 -2.49907422e+00 -9.94326830e-01 -9.34339166e-01\n   -2.33947325e+00  3.97090316e-01 -1.97622597e+00  7.82960951e-01\n   -1.66671896e+00 -1.67090249e+00  3.49327826e+00 -1.63959682e+00\n   -7.92434335e-01]\n  [-1.56664228e+00 -9.09008801e-01 -2.55426025e+00 -1.67924631e+00\n    4.24466133e+00 -2.03174639e+00  1.29308030e-01 -2.22850084e+00\n   -1.79887152e+00  2.96674061e+00 -1.75290918e+00 -1.73300242e+00\n   -2.09866381e+00 -2.51549268e+00 -1.06058490e+00 -9.93832946e-01\n   -2.40801382e+00  4.37218070e-01 -2.11224580e+00  9.06435251e-01\n   -1.75566459e+00 -1.77063382e+00  3.65295720e+00 -1.75033057e+00\n   -8.56553257e-01]\n  [-1.64533603e+00 -9.54381645e-01 -2.67193556e+00 -1.73362339e+00\n    4.29760075e+00 -2.12879181e+00  1.27127022e-01 -2.33428216e+00\n   -1.93778300e+00  3.12290001e+00 -1.81807768e+00 -1.81277919e+00\n   -2.13680053e+00 -2.51650929e+00 -1.11463296e+00 -1.04285538e+00\n   -2.45849800e+00  4.77018774e-01 -2.22167158e+00  1.01073170e+00\n   -1.82632244e+00 -1.85204399e+00  3.77180338e+00 -1.83891237e+00\n   -9.10067737e-01]\n  [-1.70823479e+00 -9.90620613e-01 -2.76249194e+00 -1.77565813e+00\n    4.33052158e+00 -2.20744848e+00  1.22315109e-01 -2.41315174e+00\n   -2.04781985e+00  3.24358320e+00 -1.86803603e+00 -1.87547445e+00\n   -2.16489744e+00 -2.50873661e+00 -1.15625048e+00 -1.08239555e+00\n   -2.49450898e+00  5.14250994e-01 -2.30770206e+00  1.09597874e+00\n   -1.88092184e+00 -1.91715193e+00  3.85937214e+00 -1.90688705e+00\n   -9.53598320e-01]\n  [-1.75728726e+00 -1.01886225e+00 -2.83137941e+00 -1.80789316e+00\n    4.35152626e+00 -2.27021503e+00  1.16151929e-01 -2.47161222e+00\n   -2.13361073e+00  3.33527040e+00 -1.90626860e+00 -1.92423058e+00\n   -2.18623781e+00 -2.49713326e+00 -1.18731976e+00 -1.11348593e+00\n   -2.52104139e+00  5.46323836e-01 -2.37537503e+00  1.16310060e+00\n   -1.92182994e+00 -1.96824634e+00  3.92363381e+00 -1.95834088e+00\n   -9.88044679e-01]\n  [-1.91986752e+00 -1.21830511e+00 -2.99411631e+00 -1.96000576e+00\n    3.97126031e+00 -2.28927159e+00  2.37885118e-01 -2.58513951e+00\n   -2.45486808e+00  3.58908939e+00 -2.08224154e+00 -2.20110917e+00\n   -2.13259149e+00 -2.29796243e+00 -1.36913347e+00 -1.23996937e+00\n   -2.59983301e+00  6.47677302e-01 -2.47770739e+00  1.46547019e+00\n   -2.09662175e+00 -2.12802529e+00  3.98179030e+00 -1.83895612e+00\n   -1.17376995e+00]\n  [-2.05739450e+00 -1.32616770e+00 -2.88573170e+00 -1.94269991e+00\n    3.46185470e+00 -2.27356386e+00  3.43162537e-01 -2.45528531e+00\n   -2.24104595e+00  3.52734423e+00 -2.15300751e+00 -2.26553583e+00\n   -2.07247162e+00 -2.08808684e+00 -1.43825877e+00 -1.26238453e+00\n   -2.42135787e+00  9.06012058e-01 -2.44201064e+00  1.81165874e+00\n   -2.18249846e+00 -2.26036382e+00  3.58306789e+00 -1.77161479e+00\n   -1.28107965e+00]\n  [-2.27864265e+00 -1.61150098e+00 -3.16333580e+00 -1.96101308e+00\n    2.61253142e+00 -2.42477703e+00  6.10782444e-01 -2.62328506e+00\n   -2.88334179e+00  3.76980162e+00 -2.42868662e+00 -2.64374495e+00\n   -1.80402815e+00 -1.62576008e+00 -1.68860352e+00 -1.52725446e+00\n   -2.26824903e+00  1.37527955e+00 -2.64471912e+00  2.34488630e+00\n   -2.51081085e+00 -2.54962492e+00  3.56614709e+00 -1.83502138e+00\n   -1.54877102e+00]\n  [-2.46555376e+00 -1.74843097e+00 -2.71645975e+00 -1.91220939e+00\n    1.69566083e+00 -2.35061407e+00  3.93592685e-01 -2.10514569e+00\n   -2.78578663e+00  3.55223942e+00 -2.44381857e+00 -2.71743965e+00\n   -1.55060363e+00 -8.45529497e-01 -1.76569641e+00 -1.58616889e+00\n   -1.95600557e+00  1.67881560e+00 -2.52741599e+00  2.72768879e+00\n   -2.53758049e+00 -2.69530988e+00  2.39150095e+00 -1.46444631e+00\n   -1.78499460e+00]\n  [-2.48394799e+00 -1.73713779e+00 -2.43921781e+00 -1.45329762e+00\n    9.42614734e-01 -2.34704828e+00  3.40716273e-01 -1.93325889e+00\n   -2.68374920e+00  3.04502726e+00 -2.41425252e+00 -2.65162563e+00\n   -1.26240277e+00 -4.36915845e-01 -1.74645865e+00 -1.65075183e+00\n   -1.64015853e+00  2.19336605e+00 -2.46553946e+00  2.80886412e+00\n   -2.43497944e+00 -2.67572999e+00  1.73232675e+00 -1.29546905e+00\n   -1.85643208e+00]\n  [-2.33410001e+00 -1.71222949e+00 -2.07820797e+00 -1.34371448e+00\n    4.07756776e-01 -2.13539863e+00  3.31679255e-01 -1.56751049e+00\n   -2.42610955e+00  2.52346420e+00 -2.30374312e+00 -2.60936880e+00\n   -1.06659043e+00 -1.39485121e-01 -1.67984354e+00 -1.62743783e+00\n   -1.30738652e+00  2.36100245e+00 -2.19667482e+00  2.68985915e+00\n   -2.37437367e+00 -2.56129813e+00  1.17889333e+00 -9.83254910e-01\n   -1.77629137e+00]]], shape=(1, 20, 25), dtype=float32)\nArgmax Indices (Recommendations per Time Step):\n[[ 4  4  4  4  4  4  4  4  4  4  4  4  4  4 22 22  9  9  9 19]]\n(1, 20, 25)\n[4, 22, 9, 17, 19, 6, 24, 1, 15, 14]\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}