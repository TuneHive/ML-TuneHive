{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.api.layers import Dense, Embedding, GRU, LeakyReLU, Concatenate, Masking, Layer\n",
    "from keras.api import Input\n",
    "from keras.api.models import Model\n",
    "from keras.api.losses import SparseCategoricalCrossentropy\n",
    "from keras.api.metrics import SparseCategoricalAccuracy, Mean, TopKCategoricalAccuracy\n",
    "from transformers.models.bert import TFBertTokenizer, TFBertEmbeddings  # embedding and tokenizer for description/nlp related stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sequences = []\n",
    "item_feature_sequences = []\n",
    "next_item_sequences = [] # target features (next item for each sequences)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((item_sequences, item_feature_sequences, next_item_sequences))\n",
    "\n",
    "def preprocesses_data(sequence):\n",
    "    # add sliding windows of sequence\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemFeatureEmbedding(Layer):\n",
    "    def __init__(self, num_features, num_items, item_embed_dim, feature_embed_dim):\n",
    "        super(ItemFeatureEmbedding, self).__init__()\n",
    "        self.feature_embedding = Embedding(input_dim=num_features, output_dim=feature_embed_dim)\n",
    "        self.item_embedding = Embedding(input_dim=num_items, output_dim=item_embed_dim, mask_zero=True)\n",
    "    \n",
    "    def call(self, items, features):\n",
    "        items_embedded = self.item_embedding(items)\n",
    "        features_embedded = self.feature_embedding(features)\n",
    "        return items_embedded, features_embedded\n",
    "\n",
    "class GRU4REC(Model):\n",
    "    def __init__(self, k, num_features, num_items, rnn_params, item_embed_dim, feature_embed_dim, ffn1_units, feature_dense_units):\n",
    "        super(GRU4REC, self).__init__()\n",
    "        self.k = k\n",
    "        self.embedding = ItemFeatureEmbedding(num_features, num_items, item_embed_dim, feature_embed_dim)\n",
    "        \n",
    "        # RNN layers\n",
    "        self.rnn = []\n",
    "        self.rnn.append(GRU(**rnn_params[0], return_sequences=True))\n",
    "        for i in range(1, len(rnn_params)-1):\n",
    "            self.rnn.append(GRU(**rnn_params[i], return_sequences=True)) # this layer will have two inputs (from embedding layer, or from previous GRU layer)\n",
    "        \n",
    "        self.rnn.append(GRU(**rnn_params[-1], return_sequences=False))\n",
    "        \n",
    "        self.concat = Concatenate(axis=-1)\n",
    "        \n",
    "        # feed-forward layer\n",
    "        self.feature_dense = Dense(feature_dense_units, activation='relu')\n",
    "        self.ffn1 = Dense(ffn1_units)\n",
    "        self.activation1 = LeakyReLU(alpha=0.2)\n",
    "        self.out = Dense(k, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        item_sequences, item_features = inputs\n",
    "        \n",
    "        # Embed items\n",
    "        item_embedded, feature_embedded = self.embedding(item_sequences, item_features)\n",
    "        \n",
    "        feature_transformed = self.feature_dense(feature_embedded)\n",
    "        \n",
    "        x = self.rnn[0](item_embedded)\n",
    "        for i in range(1, len(self.rnn)):\n",
    "            x = self.concat([item_embedded, x])\n",
    "            x = self.rnn[i](x)\n",
    "        \n",
    "        x = self.concat([x, feature_transformed])\n",
    "        x = self.ffn1(x)\n",
    "        x = self.activation1(x)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_gru4rec(model, dataset, optimizer, loss_fn, num_epochs, top_k=5):\n",
    "    \"\"\"Custom training loop for GRU4REC.\"\"\"\n",
    "    # Metrics to track loss and top k precision\n",
    "    train_loss = Mean(name='train_loss')\n",
    "    \n",
    "    train_top_k_precision = TopKCategoricalAccuracy(k=top_k, name='train_top_k_precision')\n",
    "    \n",
    "    loss_history = []\n",
    "    metrics_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Reset metrics at the start of each epoch\n",
    "        train_loss.reset_state()\n",
    "        train_top_k_precision.reset_state()\n",
    "\n",
    "        # Iterate over the dataset\n",
    "        for batch, (item_sequences, item_features, labels) in enumerate(dataset):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Forward pass\n",
    "                predictions = model((item_sequences, item_features), training=True)\n",
    "                loss = loss_fn(labels, predictions)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # Update metrics\n",
    "            train_loss.update_state(loss)\n",
    "            train_top_k_precision.update_state(labels, predictions)\n",
    "\n",
    "            print(f\"Batch {batch}, Loss: {train_loss.result().numpy():.4f}, \"\n",
    "                f\"Accuracy: {train_top_k_precision.result().numpy():.4f}\")\n",
    "\n",
    "        epoch_loss = train_loss.result().numpy()\n",
    "        epoch_top_k_precision = train_top_k_precision.result().numpy()\n",
    "        loss_history.append(epoch_loss)\n",
    "        metrics_history.append(epoch_top_k_precision)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, \"\n",
    "              f\"Accuracy: {epoch_top_k_precision:.4f}\")\n",
    "    \n",
    "    plot_training_history(loss_history, metrics_history, f'Precision@{top_k}', top_k)\n",
    "\n",
    "def plot_training_history(loss_history, metric_history, metric_name, top_k):\n",
    "    \"\"\"Plot the training loss and accuracy.\"\"\"\n",
    "    epochs = range(1, len(loss_history) + 1)\n",
    "    \n",
    "    # Create subplots for loss and accuracy\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    # Plot the training loss\n",
    "    ax1.plot(epochs, loss_history, label='Loss', color='blue', linestyle='-', marker='o')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot the top-k accuracy\n",
    "    ax2.plot(epochs, metric_history, label=metric_name, color='green', linestyle='-', marker='o')\n",
    "    ax2.set_title(f'Training {metric_name}')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel(f'{metric_name}')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gru_4_rec = GRU4REC()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
